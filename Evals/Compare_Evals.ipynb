{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9aa2dc6b",
   "metadata": {},
   "source": [
    "# Model Comparison on Summarization Tasks\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/togethercomputer/together-cookbook/blob/main/Evals/Compare_Evals.ipynb)\n",
    "\n",
    "<img src=\"../images/compare_eval.png\" width=\"750\">\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook demonstrates how to compare two language models on a summarization task using the Together AI Evaluations API. We'll:\n",
    "\n",
    "1. Load the SummEval dataset containing news articles to summarize\n",
    "2. Configure two models for comparison\n",
    "3. Use a judge model to evaluate which summaries are better\n",
    "4. Analyze the head-to-head comparison results\n",
    "\n",
    "You can also find out more about the Evaluations API in the [docs](https://docs.together.ai/docs/ai-evaluations)!\n",
    "\n",
    "The full list of supported models can be found [here](https://docs.together.ai/docs/evaluations-supported-models).\n",
    "\n",
    "\n",
    "**Concepts Covered:**\n",
    "- **LLM-as-a-Judge**: Using a language model to evaluate and compare outputs from other models\n",
    "- **Compare Evaluation**: Head-to-head comparison between two models to determine which performs better\n",
    "- **Summarization Evaluation**: Assessing summary quality across multiple criteria (accuracy, completeness, clarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae764b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup and installation\n",
    "!pip install -qU together datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3daef6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import together\n",
    "\n",
    "together_client = together.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ed3ca8",
   "metadata": {},
   "source": [
    "#### Let's imagine that we want to compare the performance of our models on a task‚Äîin this case, summarization. We will use the SummEval dataset, which contains media articles that we will summarize."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d307fe1",
   "metadata": {},
   "source": [
    "## üìä Understanding the SummEval Dataset\n",
    "\n",
    "The SummEval dataset contains news articles paired with both human and machine-generated summaries, along with quality ratings across multiple dimensions like relevance, coherence, fluency, and consistency.\n",
    "\n",
    "**Dataset Structure:**\n",
    "- `text`: The original news article to be summarized\n",
    "- `machine_summaries`: Various automated summaries\n",
    "- `human_summaries`: Human-written reference summaries\n",
    "- Quality ratings across multiple evaluation criteria\n",
    "\n",
    "For our evaluation, we'll focus on the original articles and generate new summaries using our target models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58e13d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71d34c4753bc45d9918f442f1bd094ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a161a26c5d2d4aafac8374c5f95c1ace",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dataset_infos.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "553fae6aac6c4d5486b0092dd1b69ef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/test-00000-of-00001-35901af5f664939(‚Ä¶):   0%|          | 0.00/423k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f7e44511fdd4a69929bf87bf1aef1f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['machine_summaries', 'human_summaries', 'relevance', 'coherence', 'fluency', 'consistency', 'text', 'id'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "summ_eval = load_dataset(\"mteb/summeval\")\n",
    "\n",
    "summ_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8e88c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>machine_summaries</th>\n",
       "      <th>human_summaries</th>\n",
       "      <th>relevance</th>\n",
       "      <th>coherence</th>\n",
       "      <th>fluency</th>\n",
       "      <th>consistency</th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[donald sterling , nba team last year . sterli...</td>\n",
       "      <td>[V. Stiviano must pay back $2.6 million in gif...</td>\n",
       "      <td>[1.6666666666666667, 1.6666666666666667, 2.333...</td>\n",
       "      <td>[1.3333333333333333, 3.0, 1.0, 2.6666666666666...</td>\n",
       "      <td>[1.0, 4.666666666666667, 4.333333333333333, 4....</td>\n",
       "      <td>[1.0, 2.3333333333333335, 4.666666666666667, 5...</td>\n",
       "      <td>(CNN)Donald Sterling's racist remarks cost him...</td>\n",
       "      <td>cnn-test-404f859482d47c127868964a9a39d1a7645dd2e9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[north pacific gray whale has earned a spot in...</td>\n",
       "      <td>[The whale, Varvara, swam a round trip from Ru...</td>\n",
       "      <td>[2.3333333333333335, 4.666666666666667, 3.6666...</td>\n",
       "      <td>[1.3333333333333333, 4.666666666666667, 3.6666...</td>\n",
       "      <td>[1.0, 5.0, 4.666666666666667, 3.66666666666666...</td>\n",
       "      <td>[1.3333333333333333, 5.0, 5.0, 4.3333333333333...</td>\n",
       "      <td>(CNN)A North Pacific gray whale has earned a s...</td>\n",
       "      <td>cnn-test-4761dc6d8bdf56b9ada97104113dd1bcf4aed3f1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[russian fighter jet intercepted a u.s. reconn...</td>\n",
       "      <td>[The incident occurred on April 7 north of Pol...</td>\n",
       "      <td>[4.0, 4.0, 4.0, 3.3333333333333335, 3.33333333...</td>\n",
       "      <td>[3.3333333333333335, 4.333333333333333, 1.6666...</td>\n",
       "      <td>[3.6666666666666665, 4.333333333333333, 5.0, 4...</td>\n",
       "      <td>[5.0, 5.0, 4.666666666666667, 5.0, 5.0, 5.0, 5...</td>\n",
       "      <td>(CNN)After a Russian fighter jet intercepted a...</td>\n",
       "      <td>cnn-test-5139ccfabee55ddb83e7937f5802c0a67aee8975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[michael barnett captured the fire on intersta...</td>\n",
       "      <td>[Country band Lady Antebellum's bus caught fir...</td>\n",
       "      <td>[2.0, 3.0, 2.6666666666666665, 3.3333333333333...</td>\n",
       "      <td>[2.0, 3.0, 2.6666666666666665, 3.3333333333333...</td>\n",
       "      <td>[2.6666666666666665, 5.0, 5.0, 5.0, 5.0, 5.0, ...</td>\n",
       "      <td>[2.3333333333333335, 5.0, 5.0, 5.0, 5.0, 5.0, ...</td>\n",
       "      <td>(CNN)Lady Antebellum singer Hillary Scott's to...</td>\n",
       "      <td>cnn-test-88c2481234e763c9bbc68d0ab1be1d2375c1349a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[deep reddish color caught seattle native tim ...</td>\n",
       "      <td>[Smoke from massive fires in Siberia created f...</td>\n",
       "      <td>[1.6666666666666667, 3.6666666666666665, 3.333...</td>\n",
       "      <td>[1.6666666666666667, 3.6666666666666665, 1.666...</td>\n",
       "      <td>[5.0, 5.0, 5.0, 5.0, 4.666666666666667, 5.0, 5...</td>\n",
       "      <td>[2.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, ...</td>\n",
       "      <td>(CNN)A fiery sunset greeted people in Washingt...</td>\n",
       "      <td>cnn-test-a02e362c5b8f049848ce718b37b96117485461cf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   machine_summaries  \\\n",
       "0  [donald sterling , nba team last year . sterli...   \n",
       "1  [north pacific gray whale has earned a spot in...   \n",
       "2  [russian fighter jet intercepted a u.s. reconn...   \n",
       "3  [michael barnett captured the fire on intersta...   \n",
       "4  [deep reddish color caught seattle native tim ...   \n",
       "\n",
       "                                     human_summaries  \\\n",
       "0  [V. Stiviano must pay back $2.6 million in gif...   \n",
       "1  [The whale, Varvara, swam a round trip from Ru...   \n",
       "2  [The incident occurred on April 7 north of Pol...   \n",
       "3  [Country band Lady Antebellum's bus caught fir...   \n",
       "4  [Smoke from massive fires in Siberia created f...   \n",
       "\n",
       "                                           relevance  \\\n",
       "0  [1.6666666666666667, 1.6666666666666667, 2.333...   \n",
       "1  [2.3333333333333335, 4.666666666666667, 3.6666...   \n",
       "2  [4.0, 4.0, 4.0, 3.3333333333333335, 3.33333333...   \n",
       "3  [2.0, 3.0, 2.6666666666666665, 3.3333333333333...   \n",
       "4  [1.6666666666666667, 3.6666666666666665, 3.333...   \n",
       "\n",
       "                                           coherence  \\\n",
       "0  [1.3333333333333333, 3.0, 1.0, 2.6666666666666...   \n",
       "1  [1.3333333333333333, 4.666666666666667, 3.6666...   \n",
       "2  [3.3333333333333335, 4.333333333333333, 1.6666...   \n",
       "3  [2.0, 3.0, 2.6666666666666665, 3.3333333333333...   \n",
       "4  [1.6666666666666667, 3.6666666666666665, 1.666...   \n",
       "\n",
       "                                             fluency  \\\n",
       "0  [1.0, 4.666666666666667, 4.333333333333333, 4....   \n",
       "1  [1.0, 5.0, 4.666666666666667, 3.66666666666666...   \n",
       "2  [3.6666666666666665, 4.333333333333333, 5.0, 4...   \n",
       "3  [2.6666666666666665, 5.0, 5.0, 5.0, 5.0, 5.0, ...   \n",
       "4  [5.0, 5.0, 5.0, 5.0, 4.666666666666667, 5.0, 5...   \n",
       "\n",
       "                                         consistency  \\\n",
       "0  [1.0, 2.3333333333333335, 4.666666666666667, 5...   \n",
       "1  [1.3333333333333333, 5.0, 5.0, 4.3333333333333...   \n",
       "2  [5.0, 5.0, 4.666666666666667, 5.0, 5.0, 5.0, 5...   \n",
       "3  [2.3333333333333335, 5.0, 5.0, 5.0, 5.0, 5.0, ...   \n",
       "4  [2.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, ...   \n",
       "\n",
       "                                                text  \\\n",
       "0  (CNN)Donald Sterling's racist remarks cost him...   \n",
       "1  (CNN)A North Pacific gray whale has earned a s...   \n",
       "2  (CNN)After a Russian fighter jet intercepted a...   \n",
       "3  (CNN)Lady Antebellum singer Hillary Scott's to...   \n",
       "4  (CNN)A fiery sunset greeted people in Washingt...   \n",
       "\n",
       "                                                  id  \n",
       "0  cnn-test-404f859482d47c127868964a9a39d1a7645dd2e9  \n",
       "1  cnn-test-4761dc6d8bdf56b9ada97104113dd1bcf4aed3f1  \n",
       "2  cnn-test-5139ccfabee55ddb83e7937f5802c0a67aee8975  \n",
       "3  cnn-test-88c2481234e763c9bbc68d0ab1be1d2375c1349a  \n",
       "4  cnn-test-a02e362c5b8f049848ce718b37b96117485461cf  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summ_eval['test'].to_pandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baccd900",
   "metadata": {},
   "source": [
    "We are only interested in the 'text' collumn from this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31cec5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(CNN)Donald Sterling's racist remarks cost him an NBA team last year. But now it's his former female companion who has lost big. A Los Angeles judge has ordered V. Stiviano to pay back more than $2.6 million in gifts after Sterling's wife sued her. In the lawsuit, Rochelle \"Shelly\" Sterling accused Stiviano of targeting extremely wealthy older men. She claimed Donald Sterling used the couple's money to buy Stiviano a Ferrari, two Bentleys and a Range Rover, and that he helped her get a $1.8 million duplex. Who is V. Stiviano? Stiviano countered that there was nothing wrong with Donald Sterling giving her gifts and that she never took advantage of the former Los Angeles Clippers owner, who made much of his fortune in real estate. Shelly Sterling was thrilled with the court decision Tuesday, her lawyer told CNN affiliate KABC. \"This is a victory for the Sterling family in recovering the $2,630,000 that Donald lavished on a conniving mistress,\" attorney Pierce O'Donnell said in a statement. \"It also sets a precedent that the injured spouse can recover damages from the recipient of these ill-begotten gifts.\" Stiviano's gifts from Donald Sterling didn't just include uber-expensive items like luxury cars. According to the Los Angeles Times, the list also includes a $391 Easter bunny costume, a $299 two-speed blender and a $12 lace thong. Donald Sterling's downfall came after an audio recording surfaced of the octogenarian arguing with Stiviano. In the tape, Sterling chastises Stiviano for posting pictures on social media of her posing with African-Americans, including basketball legend Magic Johnson. \"In your lousy f**ing Instagrams, you don't have to have yourself with -- walking with black people,\" Sterling said in the audio first posted by TMZ. He also tells Stiviano not to bring Johnson to Clippers games and not to post photos with the Hall of Famer so Sterling's friends can see. \"Admire him, bring him here, feed him, f**k him, but don't put (Magic) on an Instagram for the world to have to see so they have to call me,\" Sterling said. NBA Commissioner Adam Silver banned Sterling from the league, fined him $2.5 million and pushed through a charge to terminate all of his ownership rights in the franchise. Fact check: Donald Sterling's claims vs. reality CNN's Dottie Evans contributed to this report.\n"
     ]
    }
   ],
   "source": [
    "print(summ_eval['test'][0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c33fd0",
   "metadata": {},
   "source": [
    "## üîÑ Preparing Data for Evaluation\n",
    "\n",
    "Before running our comparison, we need to convert the dataset to JSONL format and upload it to the Together AI platform.\n",
    "\n",
    "The evaluation service requires:\n",
    "- JSONL format with consistent fields across all examples\n",
    "- Upload with `purpose=\"eval\"` to indicate evaluation usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60e2fbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading file tmppe44tfe9.jsonl: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 213k/213k [00:00<00:00, 273kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file: id='file-a68311f2-0204-4e30-92cc-f2a7d79621d9' object='file' created_at=1762947889 type=None purpose=<FilePurpose.Eval: 'eval'> filename='tmppe44tfe9.jsonl' bytes=213087 line_count=0 processed=True FileType='jsonl' project_id='proj_CPqRA6krcdajTs4Ey7kEa' organization_id='org_CPqRA6kbzxtyMnZvHWk9g'\n"
     ]
    }
   ],
   "source": [
    "# Convert the 'text' column to JSONL format and upload for evaluation\n",
    "import tempfile\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Create a temporary file with JSONL format\n",
    "with tempfile.NamedTemporaryFile(mode='w', suffix='.jsonl', delete=False) as f:\n",
    "    for item in summ_eval['test']:\n",
    "        json.dump({'text': item['text']}, f)\n",
    "        f.write('\\n')\n",
    "    temp_file_path = f.name\n",
    "\n",
    "# Upload the file using together_client\n",
    "uploaded_file = together_client.files.upload(\n",
    "    file=temp_file_path,\n",
    "    purpose='eval'\n",
    ")\n",
    "\n",
    "# Clean up the temporary file\n",
    "os.unlink(temp_file_path)\n",
    "\n",
    "print(f\"Uploaded file: {uploaded_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e025f47e",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Model Configuration\n",
    "\n",
    "We'll compare two models on the summarization task:\n",
    "- **Model A**: First model for comparison\n",
    "- **Model B**: Second model for comparison  \n",
    "- **Judge Model**: Evaluates which summary is better based on our criteria\n",
    "\n",
    "The judge will assess summaries across multiple dimensions including accuracy, completeness, conciseness, clarity, and relevance.\n",
    "\n",
    "We use the prompts below to setup the models being evaluated and the Judge LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84ad5aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarization_generation_template = \"\"\"You are an expert summarizer. \n",
    "Your task is to create a concise, accurate summary.\n",
    "\n",
    "INSTRUCTIONS:\n",
    "- Read the text carefully\n",
    "- Extract the main points and key information\n",
    "- Write 2-3 clear, focused sentences\n",
    "- Prioritize the most important aspects\n",
    "\"\"\"\n",
    "\n",
    "compare_judge_template = \"\"\"You are an expert judge evaluating the quality of text summaries. Your task is to compare two summaries and determine which one is better.\n",
    "\n",
    "EVALUATION CRITERIA:\n",
    "1. **Accuracy & Faithfulness**: Does the summary accurately represent the source text without hallucinations or distortions?\n",
    "2. **Completeness**: Does the summary capture all key points and main ideas from the source text?\n",
    "3. **Conciseness**: Is the summary appropriately brief while maintaining essential information?\n",
    "4. **Clarity & Readability**: Is the summary well-written, coherent, and easy to understand?\n",
    "5. **Relevance**: Does the summary focus on the most important aspects of the source text?\n",
    "\n",
    "INSTRUCTIONS:\n",
    "- Read the source text carefully\n",
    "- Evaluate both Summary A and Summary B against each criterion\n",
    "- Consider the overall quality and usefulness of each summary\n",
    "- Give a brief explanation (2-3 sentences) justifying your choice\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "880c7b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_A_NAME = \"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\"\n",
    "MODEL_B_NAME = \"Qwen/Qwen2.5-72B-Instruct-Turbo\"\n",
    "\n",
    "JUDGE_MODEL_NAME = \"deepseek-ai/DeepSeek-V3\"\n",
    "\n",
    "# Model configurations\n",
    "model_a_config = {\n",
    "    \"model\": MODEL_A_NAME,\n",
    "    \"model_source\": \"serverless\",\n",
    "    \"system_template\": summarization_generation_template,\n",
    "    \"input_template\": \"{{text}}\",\n",
    "    \"max_tokens\": 1024,\n",
    "    \"temperature\": 0.5\n",
    "}\n",
    "\n",
    "model_b_config = {\n",
    "    \"model\": MODEL_B_NAME,\n",
    "    \"model_source\": \"serverless\",\n",
    "    \"system_template\": summarization_generation_template,\n",
    "    \"input_template\": \"{{text}}\",\n",
    "    \"max_tokens\": 1024,\n",
    "    \"temperature\": 0.5\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675a2de5",
   "metadata": {},
   "source": [
    "## üèÉ‚Äç‚ôÇÔ∏è Running the Comparison Evaluation\n",
    "\n",
    "The `compare` evaluation type performs a comprehensive head-to-head comparison:\n",
    "\n",
    "1. **Two-pass evaluation**: Each model generates responses in different orders to eliminate position bias \n",
    "2. **Judge assessment**: The judge model evaluates both outputs and determines the winner\n",
    "3. **Detailed feedback**: Provides reasoning for each decision\n",
    "\n",
    "**Key Parameters:**\n",
    "- `type`: Set to `\"compare\"` for head-to-head evaluation\n",
    "- `model_a` / `model_b`: Configurations for the two models being compared\n",
    "- `judge_model_name`: The model that will make the comparison decisions\n",
    "- `judge_system_template`: Detailed criteria for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e6947a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation ID: eval-7f46-1762947944\n",
      "Status: EvaluationStatus.PENDING\n"
     ]
    }
   ],
   "source": [
    "# Create compare evaluation\n",
    "evaluation_response = together_client.evaluation.create(\n",
    "    type=\"compare\",\n",
    "    input_data_file_path=uploaded_file.id,\n",
    "    judge_model=JUDGE_MODEL_NAME,\n",
    "    judge_model_source=\"serverless\",\n",
    "    judge_system_template=compare_judge_template,\n",
    "    model_a=model_a_config,\n",
    "    model_b=model_b_config\n",
    ")\n",
    "\n",
    "print(f\"Evaluation ID: {evaluation_response.workflow_id}\")\n",
    "print(f\"Status: {evaluation_response.status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8ee809",
   "metadata": {},
   "source": [
    "## üìä Understanding Comparison Results\n",
    "\n",
    "Once the evaluation is completed we can examine the results.\n",
    "\n",
    "The evaluation provides several key metrics:\n",
    "- **A_wins**: Number of times Model A was preferred\n",
    "- **B_wins**: Number of times Model B was preferred  \n",
    "- **Ties**: Number of cases where both models performed equally\n",
    "- **Fail counts**: Generation or judge failures (should be 0 for successful runs)\n",
    "\n",
    "\n",
    "Each result includes both the original and flipped evaluations to ensure that position bias from the judge is eliminated:\n",
    "\n",
    "### Two-Pass Evaluation Process\n",
    "1. **First pass**: Model A generates first, then Model B\n",
    "2. **Second pass**: Model B generates first, then Model A\n",
    "\n",
    "Here we see that model B won in 28 cases, model A won in 21 cases, and 51 cases were ties according to our judge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27f5e310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"A_wins\": 16,\n",
      "  \"B_wins\": 29,\n",
      "  \"Ties\": 55,\n",
      "  \"generation_fail_count\": 0,\n",
      "  \"judge_fail_count\": 0,\n",
      "  \"result_file_id\": \"file-6fe32f89-8f92-443b-a832-1f99a7ab3858\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "status_compare_models = together_client.evaluation.status(evaluation_response.workflow_id)\n",
    "\n",
    "print(json.dumps(status_compare_models.results, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971e0b9f",
   "metadata": {},
   "source": [
    "## üîç Examining Detailed Results\n",
    "\n",
    "Each evaluation result contains:\n",
    "- **Original input**: The text that was summarized\n",
    "- **Model outputs**: Summaries from both Model A and Model B\n",
    "- **Judge decisions**: Both original and flipped evaluation results\n",
    "- **Final decision**: The conclusive winner after bias elimination\n",
    "\n",
    "The `final_decision` field shows the judge's ultimate verdict after considering both evaluation passes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d1bb4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file summary_bench_results_a.jsonl: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 421k/421k [00:00<00:00, 3.69MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FileObject(object='local', id='file-6fe32f89-8f92-443b-a832-1f99a7ab3858', filename='/Users/sorain/Documents/GitHub/together-cookbook/Evals/summary_bench_results_a.jsonl', size=420961)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COMPARE_MODELS_FILE = \"./summary_bench_results_a.jsonl\"\n",
    "\n",
    "compare_models_file_id = status_compare_models.results['result_file_id']\n",
    "together_client.files.retrieve_content(compare_models_file_id, output=COMPARE_MODELS_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b3d089b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 1:\n",
      "  text: New Zealand police are appealing to the public to help identify a man who robbed a Christchurch dairy wearing a 'distinctive' cartoon mask. The offender, snapped on security footage in a fluoro orange sweatshirt and oversized  mask, is described as being 'very tall'. He made off with the dairy's till and about $1500 in cash on Saturday, Stuff.co.nz reports. A man in a 'distinctive' cartoon mask demanded cash from owner's daughter on Saturday Police were reportedly called to the Union St dairy, in east Christchurch at about 12.30pm, after receiving reports of a masked man demanding cash from the dairy owner's daughter. Christina Chen told reporters her 30-year-old daughter ran out of the shop screaming 'robber!'. The masked man threw the cash register to the ground and took off with the till drawer and up to $1,500. 'Normally they just rob cigarettes and some more things, it's not a big issue,' Chen told Stuff.co.nz. 'But this time they were scary because they wore a mask, and we don't know who it is.' Police say there were no signs of any weapons used but that the robber remained at large. They are asking anyone with information that may help to identify this person to call Crimestoppers on 0800 555 111 or to message police online.\n",
      "  MODEL_TO_EVALUATE_OUTPUT_A: New Zealand police are seeking the public's help in identifying a tall man who robbed a Christchurch dairy on Saturday, wearing a distinctive cartoon mask and a fluoro orange sweatshirt. The offender demanded cash from the owner's daughter, threw the cash register to the ground, and made off with the till drawer containing around $1500. Police have released a description of the suspect and are urging anyone with information to contact Crimestoppers or message them online.\n",
      "  evaluation_successful: True\n",
      "  MODEL_TO_EVALUATE_OUTPUT_B: New Zealand police are seeking public assistance to identify a tall man who robbed a Christchurch dairy on Saturday, wearing a distinctive cartoon mask and a fluoro orange sweatshirt. The robber, who stole about $1,500 in cash by taking the till, is described as having been masked and unarmed, and police are urging anyone with information to contact Crimestoppers or report online.\n",
      "  choice_original: A\n",
      "  judge_feedback_original_order: Both summaries accurately represent the source text, but Summary A is more complete as it includes additional details such as the demand for cash from the owner's daughter and the act of throwing the cash register to the ground. Summary B, while concise, omits these key points, making it less comprehensive. Both summaries are clear and readable, but Summary A provides a fuller picture of the incident.\n",
      "  choice_flipped: A\n",
      "  judge_feedback_flipped_order: Both summaries accurately represent the source text, but Summary B is slightly better due to its inclusion of additional key details such as the demand for cash from the owner's daughter and the action of throwing the cash register to the ground. This makes Summary B more complete and relevant, while still maintaining conciseness and clarity.\n",
      "  final_decision: A\n",
      "  is_incomplete: False\n",
      "\n",
      "Line 2:\n",
      "  text: Ten people, including four children, have been involved in a multi-vehicle crash in Brisbane's west. Three vehicles collided on the Brisbane Valley Highway, 2km south of Fernvale, on Wednesday afternoon. A 40-year-old man with chest and shoulder injuries and a five-year-old boy with chest pain were the first patients flown out by rescue helicopter. They've been taken to the Princess Alexandra Hospital in Brisbane. Shortly after, a 27-year-old woman with arm injuries and a six-year-old girl suffering from abdominal pain were also being flown out. The three car pileup happened at¬†on the Brisbane Valley Highway, near Fernvale Six others - including an infant and two young girls - have been taken to Ipswich Hospital with minor injuries or for further assessment.¬†A man has also suffered hand lacerations and two females escaped injuries. The affected stretch of the highway has been closed off, with diversions in place south of Fernvale. The Courier-Mail reports that earlier emergency crews found one person trapped inside their vehicle and Queensland Fire and Rescue crews used hydraulic cutting gear to free them. The Rescue 500 helicopter then landed at the scene and airlifted a number of patients to hospital. Police said the highway would be closed for a few hours with diversions in place south of Fernvale.\n",
      "  MODEL_TO_EVALUATE_OUTPUT_A: A multi-vehicle crash occurred on the Brisbane Valley Highway, 2km south of Fernvale, involving ten people, including four children. Three patients were airlifted to the Princess Alexandra Hospital with serious injuries, while six others were taken to Ipswich Hospital with minor injuries or for further assessment. The affected stretch of the highway was closed, and diversions were put in place, with the highway expected to reopen after a few hours.\n",
      "  evaluation_successful: True\n",
      "  MODEL_TO_EVALUATE_OUTPUT_B: A multi-vehicle crash on the Brisbane Valley Highway, 2 km south of Fernvale, involved ten people, including four children. Five individuals, two adults and three children, were airlifted to hospitals with varying injuries, while six others were taken to Ipswich Hospital with minor injuries or for assessment. The highway was closed, and diversions were put in place as emergency crews, including Queensland Fire and Rescue, worked to free a trapped individual and transport the injured.\n",
      "  choice_original: A\n",
      "  judge_feedback_original_order: Summary A is better than Summary B because it accurately captures all key points from the source text, including the number of injured individuals, the severity of injuries, and the highway closure details. Summary A is also more concise and clearer, omitting unnecessary details while maintaining completeness. Summary B, while informative, includes slightly redundant information about the emergency crews, which does not significantly enhance the summary's usefulness.\n",
      "  choice_flipped: B\n",
      "  judge_feedback_flipped_order: Both summaries accurately represent the source text, but Summary A is more complete and detailed. It includes specific information about the injuries of the patients and the involvement of emergency crews, which Summary B omits. Summary A also maintains better clarity and readability while being concise.\n",
      "  final_decision: Tie\n",
      "  is_incomplete: False\n",
      "\n",
      "Line 3:\n",
      "  text: Cats and dogs have the advantage over marine pets in that they can interact with humans through the sense of touch. But that doesn‚Äôt prevent one man from dipping his hand in the fish tank and giving his blood parrot cichlid  a stroke. Capturing his remarkable relationship on camera, Roland Giroux gently cups the fish with his hand from within side the tank and then treats it to a massage. The fish begins relaxing in the man's hand and stays very still as the owner begins to stroke it with his finger The fish initially moves away before swimming in a full circle and returning to rest in between the man‚Äôs fingers. The man then begins massaging the pet by running his finger along it and the fish stays completely still as if enjoying the sensation. Repeating the process, the fish swims off once more before immediately returning to the man‚Äôs hand to be stroked again. Later in the video the fish interacts further with the man by swimming up his arm and circling his fingers. The man places his hand into the tank and gently cups the¬†blood parrot cichlid with his fingers Before burying its face into his hand and remaining very still once more. The video concludes with the man removing his hand from the tank and the fish, clearly saddened by this, following it up to the surface of the water. According to Mr Giroux, who uploads many videos of his fish to his Youtube channel, the blood parrot cichlid used to share its tank with two other fish. The fish swims away from the man's hand a few times in the video but returns to be massaged But he was forced to remove the other two from the tank when he noticed that they were bullying his prized pet. He then set about interacting with the fish by feeding it frozen blood worms by hand and eventually he noticed it becoming more sociable. After a while the fish enjoyed being stroked and Mr Giroux noted that it would become frustrated if he didn‚Äôt play with it on a daily basis. The fish begins swimming around the man's fingers and towards the surface as he removes his hand The man massages and plays with his fish for at least 15 minutes each day. The blood parrot cichlid is a hybrid of the midas and the redhead cichlid and was first bred in Taiwan around 1986.\n",
      "  MODEL_TO_EVALUATE_OUTPUT_A: Roland Giroux has formed a remarkable bond with his blood parrot cichlid, a hybrid fish bred in Taiwan in 1986. The fish, which was previously bullied by tankmates, has become sociable and enjoys being stroked and massaged by Giroux, who interacts with it daily for at least 15 minutes. The video shows the fish swimming up to Giroux's hand, circling his fingers, and even burying its face into his palm, highlighting the unique and affectionate relationship between the man and his pet.\n",
      "  evaluation_successful: True\n",
      "  MODEL_TO_EVALUATE_OUTPUT_B: Roland Giroux, a fish enthusiast, has developed a unique bond with his blood parrot cichlid, capturing their interaction on video. By gently stroking and massaging the fish, Giroux has fostered a level of trust and sociability, with the cichlid often returning for more attention and even following his hand when it's removed from the tank. This relationship was cultivated over time, initially by hand-feeding the fish and addressing its social needs after removing two bullying tankmates.\n",
      "  choice_original: B\n",
      "  judge_feedback_original_order: Both summaries accurately capture the unique bond between Roland Giroux and his blood parrot cichlid, but Summary B provides a slightly more concise and focused overview. It effectively highlights the development of trust and sociability through Giroux's interactions, while also mentioning the initial steps he took to build this relationship. Summary A, while detailed, includes slightly more redundant information about the fish's behavior that doesn't add significant value to the core message.\n",
      "  choice_flipped: B\n",
      "  judge_feedback_flipped_order: Summary A is better than Summary B as it more accurately captures the development of the relationship between Roland Giroux and his blood parrot cichlid, including the initial hand-feeding and the removal of bullying tankmates. It also maintains a good balance of conciseness and completeness, while Summary B focuses more on the fish's origin and less on the interaction details.\n",
      "  final_decision: B\n",
      "  is_incomplete: False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print first 3 lines of the comparison results file\n",
    "with open(COMPARE_MODELS_FILE, 'r') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= 3:\n",
    "            break\n",
    "        print(f\"Line {i+1}:\")\n",
    "        data = json.loads(line.strip())\n",
    "        for key, value in data.items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "250887ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FINAL COMPARISON RESULTS ===\n",
      "Total Evaluations: 100\n",
      "Model A - meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo Wins: 16 (16.0%)\n",
      "Model B - Qwen/Qwen2.5-72B-Instruct-Turbo Wins: 29 (29.0%)\n",
      "Ties: 55 (55.0%)\n",
      "\n",
      "üèÜ Winner: Model B - Qwen/Qwen2.5-72B-Instruct-Turbo by 13 evaluations\n"
     ]
    }
   ],
   "source": [
    "# Calculate and display final results\n",
    "total_comparisons = status_compare_models.results['A_wins'] + status_compare_models.results['B_wins'] + status_compare_models.results['Ties']\n",
    "a_wins = status_compare_models.results['A_wins']\n",
    "b_wins = status_compare_models.results['B_wins']  \n",
    "ties = status_compare_models.results['Ties']\n",
    "\n",
    "print(\"=== FINAL COMPARISON RESULTS ===\")\n",
    "print(f\"Total Evaluations: {total_comparisons}\")\n",
    "print(f\"Model A - {MODEL_A_NAME} Wins: {a_wins} ({a_wins/total_comparisons*100:.1f}%)\")\n",
    "print(f\"Model B - {MODEL_B_NAME} Wins: {b_wins} ({b_wins/total_comparisons*100:.1f}%)\")\n",
    "print(f\"Ties: {ties} ({ties/total_comparisons*100:.1f}%)\")\n",
    "print()\n",
    "\n",
    "if b_wins > a_wins:\n",
    "    winner = f\"Model B - {MODEL_B_NAME}\"\n",
    "    margin = b_wins - a_wins\n",
    "elif a_wins > b_wins:\n",
    "    winner = f\"Model A - {MODEL_A_NAME}\" \n",
    "    margin = a_wins - b_wins\n",
    "else:\n",
    "    winner = \"Tie\"\n",
    "    margin = 0\n",
    "\n",
    "if winner != \"Tie\":\n",
    "    print(f\"üèÜ Winner: {winner} by {margin} evaluations\")\n",
    "else:\n",
    "    print(\"ü§ù Overall tie between models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50a3a8e",
   "metadata": {},
   "source": [
    "## üîë Key Findings\n",
    "\n",
    "**Performance Summary:**\n",
    "- **Model B** outperformed Model A with **29 wins vs 16 wins** (13-point advantage)\n",
    "- **High tie rate** of **55%** suggests both models often produce comparable summaries\n",
    "- **No failures** in generation or judging indicates robust model performance\n",
    "\n",
    "**Insights:**\n",
    "- The close competition (28 vs 21) suggests both models have similar summarization capabilities\n",
    "- The high tie percentage (51%) indicates that for many articles, both models produced summaries of equivalent quality\n",
    "- Model B's slight edge may be due to better handling of specific article types or summary characteristics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
