{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSPy Agents with Together AI\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github.com/togethercomputer/together-cookbook/blob/main/Agents/DSPy/DSPy_Agents.ipynb)\n",
    "\n",
    "<img src=\"../../images/dspy.png\" width=\"700\">\n",
    "\n",
    "Let's create a DSPy agent that can search through multiple steps to find information. We will see how well the agent performs when powered by a 8b LLM and then improve it by using a 70b LLM.\n",
    "\n",
    "Adapted from [source](https://dspy.ai/tutorials/agents/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we'll use Meta's Llama-3.1-8B-Instruct-Turbo and Llama-3.3-70B-Instruct-Turbo models from Together AI.\n",
    "\n",
    "The 8B model is relatively small and fast, making it a good choice for initial development and testing.\n",
    "While it may not be as capable as larger models for complex tasks, it provides a good balance of speed and capability.\n",
    "\n",
    "The 70B model is much more powerful and will serve as our \"teacher\" model to help improve the performance\n",
    "of the smaller 8B model through DSPy's optimization techniques.\n",
    "\n",
    "In the code below, we'll configure the 8B model as our main LM and use the 70B model sparingly as a teacher\n",
    "to help optimize our agent's performance.\n",
    "\n",
    "We'll see that we can improve the agent's performance by over 20% using DSPy's MIPRO prompt optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU dspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "#ignore warnings\n",
    "import warnings, os\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings(action=\"ignore\", category=UserWarning, module=\"litellm\")  # Ignore litellm warnings\n",
    "\n",
    "TOGETHER_API_KEY = os.getenv('TOGETHER_API_KEY')\n",
    "\n",
    "llama8b = dspy.LM('together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo', api_key=TOGETHER_API_KEY, api_base='https://api.together.xyz/v1', temperature=0.7)\n",
    "\n",
    "llama3_70b = dspy.LM('together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo', api_key=TOGETHER_API_KEY, api_base='https://api.together.xyz/v1', temperature=0.7)\n",
    "\n",
    "dspy.configure(lm=llama8b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"It looks like you're ready for a test. What kind of test is it? A language proficiency test, a quiz, or something else?\"]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama8b(\"Say this is a test!\", temperature=0.7)  # => ['This is a test!']\n",
    "#llama3b(messages=[{\"role\": \"user\", \"content\": \"Say this is a test!\"}])  # => ['This is a test!']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Dataset\n",
    "\n",
    "We'll load examples from the HoVer (Hover over Verifiable Claims) dataset, which contains complex multi-hop claims. For each claim, we need to identify the set of Wikipedia pages required to verify or refute it. The claims are intentionally complex, often requiring information from multiple pages to fact-check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from dspy.datasets import DataLoader\n",
    "\n",
    "kwargs = dict(fields=(\"claim\", \"supporting_facts\", \"hpqa_id\", \"num_hops\"), input_keys=(\"claim\",))\n",
    "hover = DataLoader().from_huggingface(dataset_name=\"hover-nlp/hover\", split=\"train\", trust_remote_code=True, **kwargs)\n",
    "\n",
    "hpqa_ids = set()\n",
    "hover = [\n",
    "    dspy.Example(claim=x.claim, titles=list(set([y[\"key\"] for y in x.supporting_facts]))).with_inputs(\"claim\")\n",
    "    for x in hover\n",
    "    if x[\"num_hops\"] == 3 and x[\"hpqa_id\"] not in hpqa_ids and not hpqa_ids.add(x[\"hpqa_id\"])\n",
    "]\n",
    "\n",
    "random.Random(0).shuffle(hover)\n",
    "trainset, devset, testset = hover[:100], hover[100:200], hover[650:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claim: This director is known for his work on Miss Potter. The Academy of Motion Picture Arts and Sciences presents the award in which he was nominated for his work in \"Babe\".\n",
      "Pages that must be retrieved: ['Chris Noonan', 'Academy Award for Best Director', 'Miss Potter']\n"
     ]
    }
   ],
   "source": [
    "# View an example\n",
    "example = trainset[0]\n",
    "\n",
    "print(\"Claim:\", example.claim)\n",
    "print(\"Correct pages that must be retrieved:\", example.titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Wikipedia Search\n",
    "\n",
    "Now we'll set up Wikipedia search functionality using ColBERTv2. This server indexes article abstracts (first paragraphs) from Wikipedia's 2017 dataset, which matches the data used in HoVer. The search will help us find relevant articles to verify claims."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOCS = {}\n",
    "\n",
    "def search(query: str, k: int) -> list[str]:\n",
    "    results = dspy.ColBERTv2(url='http://20.102.90.50:2017/wiki17_abstracts')(query, k=k)\n",
    "    results = [x['text'] for x in results]\n",
    "\n",
    "    for result in results:\n",
    "        title, text = result.split(\" | \", 1)\n",
    "        DOCS[title] = text\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Cuisine in Toronto | The cuisine of Toronto reflects Toronto's size and multicultural diversity. Different ethnic neighbourhoods throughout the city focus on specific cuisines, such as authentic Chinese and Vietnamese found in the city's six Chinatowns, Korean in Koreatown, Greek on The Danforth, Italian cuisine in Little Italy and Corso Italia, and Indian in Little India. Numerous other world cuisines are available throughout the city, including Portuguese, Hungarian, Japanese, and Caribbean. Toronto's large Jewish population has also ensured a variety of Jewish restaurants and delis, with varying adherence to kosher rules. In addition to ethnic cuisines, Toronto is also home to many fine dining establishments and chain restaurants ranging from fast food to casual or upscale dining.\",\n",
       " \"Fran's Restaurant | Fran's Restaurant is a small chain of restaurants based in Toronto, Ontario, Canada. Its first restaurant was a haunt of pianist Glenn Gould.\",\n",
       " 'Bistro 990 | Bistro 990 was a restaurant in Toronto, Ontario, Canada. It closed on March 17, 2012. The bistro served Provençal style French cuisine in an informal atmosphere. Throughout its run the restaurant had been owned by Tom Kristenbrun.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search(query='toronto restaurants', k = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's use the search function to define two tools for our ReAct agent:\n",
    "\n",
    "def search_wikipedia(query: str) -> list[str]:\n",
    "    \"\"\"Returns top-5 results and then the titles of the top-5 to top-30 results.\"\"\"\n",
    "\n",
    "    topK = search(query, 30)\n",
    "    titles, topK = [f\"`{x.split(' | ')[0]}`\" for x in topK[5:30]], topK[:5]\n",
    "    return topK + [f\"Other retrieved pages have titles: {', '.join(titles)}.\"]\n",
    "\n",
    "def lookup_wikipedia(title: str) -> str:\n",
    "    \"\"\"Returns the text of the Wikipedia page, if it exists.\"\"\"\n",
    "\n",
    "    if title in DOCS:\n",
    "        return DOCS[title]\n",
    "\n",
    "    results = [x for x in search(title, 10) if x.startswith(title + \" | \")]\n",
    "    if not results:\n",
    "        return f\"No Wikipedia page found for title: {title}\"\n",
    "    return results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up a Fact-Checking Agent\n",
    "\n",
    "In this section, we'll create a ReAct agent using DSPy to help with fact verification.\n",
    "The agent will have a simple but powerful task: given a claim, it will return a list\n",
    "of relevant Wikipedia article titles that can be used to verify or refute that claim.\n",
    "\n",
    "The agent will:\n",
    "1. Take a claim as input\n",
    "2. Search through Wikipedia articles\n",
    "3. Return a list[str] of article titles needed for fact-checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"Find all Wikipedia titles relevant to verifying (or refuting) the claim.\"\n",
    "signature = dspy.Signature(\"claim -> titles: list[str]\", instructions)\n",
    "react = dspy.ReAct(signature, tools=[search_wikipedia, lookup_wikipedia], max_iters=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['David Gregory (physician)',\n",
       " 'David Gregory (journalist)',\n",
       " 'David Gregory (historian)']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try our agent out\n",
    "react(claim=\"David Gregory was born in 1625.\").titles[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Evals\n",
    "\n",
    "Let's create an evaluation metric called top5_recall.\n",
    "\n",
    "This metric compares the agent's output against a gold standard set of 3 relevant Wikipedia titles.\n",
    "It calculates what fraction of those gold titles appear in the agent's top 5 predicted titles.\n",
    "For example, if 2 out of 3 gold titles are found in the top 5, the recall would be 0.67."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top5_recall(example, pred, trace=None):\n",
    "    gold_titles = example.titles\n",
    "    recall = sum(x in pred.titles[:5] for x in gold_titles) / len(gold_titles)\n",
    "\n",
    "    # If we're \"bootstrapping\" for optimization, return True if and only if the recall is perfect.\n",
    "    if trace is not None:\n",
    "        return recall >= 1.0\n",
    "    \n",
    "    # If we're just doing inference, just measure the recall.\n",
    "    return recall\n",
    "\n",
    "evaluate = dspy.Evaluate(devset=devset, metric=top5_recall, num_threads=16, display_progress=True, display_table=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate our basic ReAct agent using Llama-3.2-8B as the language model.\n",
    "This will give us a baseline performance to improve upon.\n",
    "\n",
    "Since this is a relatively small model (8B parameters), it can sometimes fail or give errors.\n",
    "We'll add error handling to gracefully handle any failures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 49.33 / 100 (49.3%): 100%|██████████| 100/100 [02:28<00:00,  1.48s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/09 00:40:21 INFO dspy.evaluate.evaluate: Average Metric: 49.33333333333333 / 100 (49.3%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim</th>\n",
       "      <th>example_titles</th>\n",
       "      <th>trajectory</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>pred_titles</th>\n",
       "      <th>top5_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Church of England's movement that inspired the Trinity Episcop...</td>\n",
       "      <td>[Samuel Rickards, Trinity Episcopal Church (Houghton, Michigan), O...</td>\n",
       "      <td>{'thought_0': \"We need to find the Wikipedia title related to the ...</td>\n",
       "      <td>To find all Wikipedia titles relevant to verifying (or refuting) t...</td>\n",
       "      <td>['John Keble', 'John Keble Church, Mill Hill', 'National Apostasy'...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Red, White &amp; Crüe and this athlete both fight. The french fighter ...</td>\n",
       "      <td>[Bobby Stewart, Red, White &amp;amp; Crüe, Mike Tyson]</td>\n",
       "      <td>{'thought_0': 'We need to find Wikipedia titles related to Red, Wh...</td>\n",
       "      <td>To verify or refute the claim, we need to find Wikipedia titles re...</td>\n",
       "      <td>['Mötley Crüe', 'Mike Tyson', 'Boxing', 'Red, White &amp; Crüe', 'Bobb...</td>\n",
       "      <td>✔️ [0.667]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The writer/director/actor from Glen or Glenda and Fernand Rivers s...</td>\n",
       "      <td>[Glen or Glenda, Fernand Rivers, Ed Wood]</td>\n",
       "      <td>{'thought_0': 'We need to find a Wikipedia title that shares the c...</td>\n",
       "      <td>The claim is verified by finding all Wikipedia titles that share t...</td>\n",
       "      <td>['Joel Hershman', 'Sid Bennett (director)', 'David H. Steinberg', ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The film by Sandi Sissel was released before The End of Suburbia.</td>\n",
       "      <td>[Chicken Ranch (film), The End of Suburbia, Sandi Sissel]</td>\n",
       "      <td>{'thought_0': 'We need to find the release dates of the films \"The...</td>\n",
       "      <td>To verify the claim that the film by Sandi Sissel was released bef...</td>\n",
       "      <td>['The End of Suburbia', 'Kailashey Kelenkari', 'The End of Suburbi...</td>\n",
       "      <td>✔️ [0.333]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The actor who played captain hook in the live production with Tayl...</td>\n",
       "      <td>[Taylor Louderman, Christopher Walken, Peter Pan Live!]</td>\n",
       "      <td>{'thought_0': 'We need to verify the claim, so the first step is t...</td>\n",
       "      <td>The claim made is that the actor who played Captain Hook in the li...</td>\n",
       "      <td>[Bruce Dern]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   claim  \\\n",
       "0  The Church of England's movement that inspired the Trinity Episcop...   \n",
       "1  Red, White & Crüe and this athlete both fight. The french fighter ...   \n",
       "2  The writer/director/actor from Glen or Glenda and Fernand Rivers s...   \n",
       "3      The film by Sandi Sissel was released before The End of Suburbia.   \n",
       "4  The actor who played captain hook in the live production with Tayl...   \n",
       "\n",
       "                                                          example_titles  \\\n",
       "0  [Samuel Rickards, Trinity Episcopal Church (Houghton, Michigan), O...   \n",
       "1                     [Bobby Stewart, Red, White &amp; Crüe, Mike Tyson]   \n",
       "2                              [Glen or Glenda, Fernand Rivers, Ed Wood]   \n",
       "3              [Chicken Ranch (film), The End of Suburbia, Sandi Sissel]   \n",
       "4                [Taylor Louderman, Christopher Walken, Peter Pan Live!]   \n",
       "\n",
       "                                                              trajectory  \\\n",
       "0  {'thought_0': \"We need to find the Wikipedia title related to the ...   \n",
       "1  {'thought_0': 'We need to find Wikipedia titles related to Red, Wh...   \n",
       "2  {'thought_0': 'We need to find a Wikipedia title that shares the c...   \n",
       "3  {'thought_0': 'We need to find the release dates of the films \"The...   \n",
       "4  {'thought_0': 'We need to verify the claim, so the first step is t...   \n",
       "\n",
       "                                                               reasoning  \\\n",
       "0  To find all Wikipedia titles relevant to verifying (or refuting) t...   \n",
       "1  To verify or refute the claim, we need to find Wikipedia titles re...   \n",
       "2  The claim is verified by finding all Wikipedia titles that share t...   \n",
       "3  To verify the claim that the film by Sandi Sissel was released bef...   \n",
       "4  The claim made is that the actor who played Captain Hook in the li...   \n",
       "\n",
       "                                                             pred_titles  \\\n",
       "0  ['John Keble', 'John Keble Church, Mill Hill', 'National Apostasy'...   \n",
       "1  ['Mötley Crüe', 'Mike Tyson', 'Boxing', 'Red, White & Crüe', 'Bobb...   \n",
       "2  ['Joel Hershman', 'Sid Bennett (director)', 'David H. Steinberg', ...   \n",
       "3  ['The End of Suburbia', 'Kailashey Kelenkari', 'The End of Suburbi...   \n",
       "4                                                           [Bruce Dern]   \n",
       "\n",
       "  top5_recall  \n",
       "0              \n",
       "1  ✔️ [0.667]  \n",
       "2              \n",
       "3  ✔️ [0.333]  \n",
       "4              "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div style='\n",
       "                    text-align: center;\n",
       "                    font-size: 16px;\n",
       "                    font-weight: bold;\n",
       "                    color: #555;\n",
       "                    margin: 10px 0;'>\n",
       "                    ... 95 more rows not displayed ...\n",
       "                </div>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "49.33"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings(action=\"ignore\", category=UserWarning, module=\"litellm\")  # Ignore litellm warnings\n",
    "\n",
    "def safe_react(claim: str):\n",
    "    try:\n",
    "        return react(claim=claim)\n",
    "    except Exception as e:\n",
    "        return dspy.Prediction(titles=[])\n",
    "\n",
    "evaluate(safe_react)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a baseline performance of 0.5 top-5 recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving over the baseline\n",
    "\n",
    "Let's try to improve this performance using DSPy's MIPRO optimizer.\n",
    "MIPRO will automatically optimize the prompts and few-shot examples used by our ReAct agent.\n",
    "We'll use a more powerful model (Llama-3-70B) as the teacher model to help guide the optimization.\n",
    "\n",
    "This may take around ~20 minutes and make some $5 worth of calls to Together AI to optimize Llama3 8B.\n",
    "\n",
    "This will give us new prompts and few-shot examples that will improve the agent's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/09 00:40:54 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "RUNNING WITH THE FOLLOWING MEDIUM AUTO RUN SETTINGS:\n",
      "num_trials: 25\n",
      "minibatch: True\n",
      "num_candidates: 9\n",
      "valset size: 80\n",
      "\n",
      "2025/03/09 00:44:54 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "==> STEP 1: BOOTSTRAP FEWSHOT EXAMPLES <==\n",
      "2025/03/09 00:44:54 INFO dspy.teleprompt.mipro_optimizer_v2: These will be used as few-shot example candidates for our program and for creating instructions.\n",
      "\n",
      "2025/03/09 00:44:54 INFO dspy.teleprompt.mipro_optimizer_v2: Bootstrapping N=9 sets of demonstrations...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapping set 1/9\n",
      "Bootstrapping set 2/9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [01:34<01:55, 10.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 9 examples for up to 1 rounds, amounting to 9 attempts.\n",
      "Bootstrapping set 3/9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [00:57<00:47,  5.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 11 examples for up to 1 rounds, amounting to 11 attempts.\n",
      "Bootstrapping set 4/9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:07<01:09,  3.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 2 examples for up to 1 rounds, amounting to 2 attempts.\n",
      "Bootstrapping set 5/9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [00:20<00:16,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 11 examples for up to 1 rounds, amounting to 11 attempts.\n",
      "Bootstrapping set 6/9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [00:07<00:09,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 9 examples for up to 1 rounds, amounting to 9 attempts.\n",
      "Bootstrapping set 7/9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:00<00:00, 98.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 4 examples for up to 1 rounds, amounting to 4 attempts.\n",
      "Bootstrapping set 8/9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:00<00:00, 90.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 2 examples for up to 1 rounds, amounting to 2 attempts.\n",
      "Bootstrapping set 9/9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [00:26<00:32,  2.92s/it]\n",
      "2025/03/09 00:48:29 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "==> STEP 2: PROPOSE INSTRUCTION CANDIDATES <==\n",
      "2025/03/09 00:48:29 INFO dspy.teleprompt.mipro_optimizer_v2: We will use the few-shot examples from the previous step, a generated dataset summary, a summary of the program code, and a randomly selected prompting tip to propose instructions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 9 examples for up to 1 rounds, amounting to 9 attempts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/09 00:48:36 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "Proposing instructions...\n",
      "\n",
      "2025/03/09 00:51:50 INFO dspy.teleprompt.mipro_optimizer_v2: Proposed Instructions for Predictor 0:\n",
      "\n",
      "2025/03/09 00:51:50 INFO dspy.teleprompt.mipro_optimizer_v2: 0: Find all Wikipedia titles relevant to verifying (or refuting) the claim.\n",
      "\n",
      "You will be given `claim` and your goal is to finish with `titles`.\n",
      "\n",
      "To do this, you will interleave Thought, Tool Name, and Tool Args, and receive a resulting Observation.\n",
      "\n",
      "Thought can reason about the current situation, and Tool Name can be the following types:\n",
      "\n",
      "(1) search_wikipedia, whose description is <desc>Returns top-5 results and then the titles of the top-5 to top-30 results.</desc>. It takes arguments {'query': {'type': 'string'}} in JSON format.\n",
      "(2) lookup_wikipedia, whose description is <desc>Returns the text of the Wikipedia page, if it exists.</desc>. It takes arguments {'title': {'type': 'string'}} in JSON format.\n",
      "(3) finish, whose description is <desc>Signals that the final outputs, i.e. `titles`, are now available and marks the task as complete.</desc>. It takes arguments {'kwargs': 'Any'} in JSON format.\n",
      "\n",
      "2025/03/09 00:51:50 INFO dspy.teleprompt.mipro_optimizer_v2: 1: To verify the given claim, you will start by analyzing the claim and identifying key entities and concepts. Then, you will use the search_wikipedia tool to find relevant Wikipedia pages related to the claim, and iterate through the results to extract useful information. If necessary, use the lookup_wikipedia tool to retrieve specific Wikipedia pages. After gathering sufficient information, use the finish tool to provide the final Wikipedia titles relevant to verifying or refuting the claim.\n",
      "\n",
      "You will be given a claim, and your goal is to finish with a list of relevant Wikipedia titles.\n",
      "\n",
      "To achieve this, you will interleave your thoughts about the current situation, choose the next tool to use, and provide the necessary arguments for that tool. The tools available are:\n",
      "\n",
      "1. search_wikipedia: This tool returns the top-5 results and then the titles of the top-5 to top-30 results. It takes a query string as an argument in JSON format.\n",
      "2. lookup_wikipedia: This tool returns the text of a specific Wikipedia page, if it exists. It takes a title string as an argument in JSON format.\n",
      "3. finish: This tool signals that the final outputs, i.e., the list of Wikipedia titles, are now available and marks the task as complete. It takes any additional information as arguments in JSON format.\n",
      "\n",
      "Keep your thoughts and actions clear and concise, and use the tools effectively to verify or refute the claim.\n",
      "\n",
      "2025/03/09 00:51:50 INFO dspy.teleprompt.mipro_optimizer_v2: 2: You are a fact-checker tasked with verifying claims by finding relevant Wikipedia titles. Find all Wikipedia titles relevant to verifying (or refuting) the claim.\n",
      "\n",
      "You will be given a `claim` and your goal is to finish with `titles`. To do this, you will interleave Thought, Tool Name, and Tool Args, and receive a resulting Observation.\n",
      "\n",
      "Thought can reason about the current situation, and Tool Name can be the following types:\n",
      "\n",
      "(1) search_wikipedia, whose description is <desc>Returns top-5 results and then the titles of the top-5 to top-30 results.</desc>. It takes arguments {'query': {'type': 'string'}} in JSON format.\n",
      "(2) lookup_wikipedia, whose description is <desc>Returns the text of the Wikipedia page, if it exists.</desc>. It takes arguments {'title': {'type': 'string'}} in JSON format.\n",
      "(3) finish, whose description is <desc>Signals that the final outputs, i.e. `titles`, are now available and marks the task as complete.</desc>. It takes arguments {'kwargs': 'Any'} in JSON format.\n",
      "\n",
      "As you work through the task, consider the claim and think about what information you need to verify or refute it. Use the search_wikipedia tool to find relevant pages, and then use the lookup_wikipedia tool to dive deeper into specific pages. Once you have gathered all the necessary information, use the finish tool to signal that you have completed the task and provide the relevant Wikipedia titles.\n",
      "\n",
      "2025/03/09 00:51:50 INFO dspy.teleprompt.mipro_optimizer_v2: 3: You are a fact-checker for a prestigious news organization, and your task is to verify the accuracy of a given claim. The claim is: \"The director of the film 'Miss Potter' was nominated for an Academy Award for his work on the film 'Babe'.\" You have access to a vast database of information, including Wikipedia. Your goal is to find all relevant Wikipedia titles that can help you verify or refute this claim. You will interleave your thought process, the tools you use to gather information, and the arguments you pass to these tools. You can use the following tools: (1) search_wikipedia, which returns the top-5 results and the titles of the top-5 to top-30 results for a given query; (2) lookup_wikipedia, which returns the text of a Wikipedia page if it exists; and (3) finish, which signals that you have found the final answers and marks the task as complete. You must provide the titles of the relevant Wikipedia pages to confirm or deny the claim. The fate of the news organization's reputation rests on your ability to accurately verify this claim.\n",
      "\n",
      "2025/03/09 00:51:50 INFO dspy.teleprompt.mipro_optimizer_v2: 4: You are a fact-checker working for a prestigious news organization, and your task is to verify the accuracy of a given claim. The claim is: \"{claim}\". You have access to a vast repository of knowledge, including Wikipedia, and you must use this resource to find relevant information that either supports or refutes the claim. Your goal is to provide a list of Wikipedia titles that are relevant to verifying the claim. You will start by analyzing the claim and deciding on the best course of action. You can use the following tools to aid in your research: (1) search_wikipedia, which returns the top-5 results and then the titles of the top-5 to top-30 results for a given query; (2) lookup_wikipedia, which returns the text of a Wikipedia page if it exists; and (3) finish, which signals that you have completed your research and are ready to provide the final list of relevant Wikipedia titles. You will interleave your thoughts, tool names, and tool arguments to receive observations that will help you refine your search. The stakes are high, as the accuracy of your fact-checking will have a significant impact on the reputation of your news organization. You must be meticulous and thorough in your research to ensure that you provide the most accurate and relevant information possible.\n",
      "\n",
      "2025/03/09 00:51:50 INFO dspy.teleprompt.mipro_optimizer_v2: 5: You are a journalist working for a prestigious news organization, and you have been assigned to verify a claim about a specific topic. Your editor has given you a tight deadline to submit your article, and the credibility of your news organization depends on the accuracy of the information you provide. The claim you need to verify is: {claim}. You have access to a powerful tool that allows you to search Wikipedia and retrieve relevant information. Your goal is to find all Wikipedia titles relevant to verifying or refuting the claim. You will start by analyzing the claim and identifying the key entities and concepts involved. Then, you will use the search tool to find relevant Wikipedia pages and extract the necessary information. You may need to perform multiple searches and use different tool names and arguments to gather all the required information. Once you have finished searching, you will use the finish tool to signal that you have completed the task and provide the final list of Wikipedia titles. You must work efficiently and accurately to meet the deadline and maintain the credibility of your news organization.\n",
      "\n",
      "You will be given `claim` and your goal is to finish with `titles`.\n",
      "\n",
      "To do this, you will interleave Thought, Tool Name, and Tool Args, and receive a resulting Observation.\n",
      "\n",
      "Thought can reason about the current situation, and Tool Name can be the following types:\n",
      "\n",
      "(1) search_wikipedia, whose description is <desc>Returns top-5 results and then the titles of the top-5 to top-30 results.</desc>. It takes arguments {'query': {'type': 'string'}} in JSON format.\n",
      "(2) lookup_wikipedia, whose description is <desc>Returns the text of the Wikipedia page, if it exists.</desc>. It takes arguments {'title': {'type': 'string'}} in JSON format.\n",
      "(3) finish, whose description is <desc>Signals that the final outputs, i.e. `titles`, are now available and marks the task as complete.</desc>. It takes arguments {'kwargs': 'Any'} in JSON format.\n",
      "\n",
      "Remember, the accuracy and credibility of your news organization depend on your ability to verify the claim and provide the correct list of Wikipedia titles. You must work carefully and efficiently to meet the deadline and achieve your goal.\n",
      "\n",
      "2025/03/09 00:51:50 INFO dspy.teleprompt.mipro_optimizer_v2: 6: To verify the claim, we need to find relevant information on Wikipedia by searching for specific keywords and looking up relevant pages. \n",
      "\n",
      "First, we will use the search_wikipedia tool to find top results related to the claim. We will analyze the observation and identify the most relevant information. \n",
      "\n",
      "If necessary, we will use the lookup_wikipedia tool to retrieve the text of specific Wikipedia pages. \n",
      "\n",
      "We will interleave thoughts, tool names, and tool arguments to receive observations and make decisions about the next steps. \n",
      "\n",
      "Our goal is to find all Wikipedia titles relevant to verifying or refuting the claim and finish with the titles.\n",
      "\n",
      "2025/03/09 00:51:50 INFO dspy.teleprompt.mipro_optimizer_v2: 7: You are a critical component in a high-stakes fact-checking mission, where the accuracy of information can make or break a major news story. Your task is to verify a claim by finding all relevant Wikipedia titles associated with it. The claim is: \"The new policy has been met with widespread criticism from environmental groups.\" You have access to three tools: search_wikipedia, lookup_wikipedia, and finish. search_wikipedia returns the top 5 results and the titles of the top 5 to 30 results for a given query, lookup_wikipedia returns the text of a Wikipedia page if it exists, and finish signals the completion of the task with the final titles. You will interleave thought, tool selection, and argument formulation to achieve your goal. Begin by reasoning about the claim and deciding on the first tool to use and its arguments.\n",
      "\n",
      "2025/03/09 00:51:50 INFO dspy.teleprompt.mipro_optimizer_v2: 8: To verify the given claim, we need to find relevant information on Wikipedia. We will start by searching for keywords related to the claim using the search_wikipedia tool. Based on the observation, we will then decide whether to refine our search, look up a specific Wikipedia page using the lookup_wikipedia tool, or finish the task by providing the relevant Wikipedia titles. Throughout the process, we will interleave our thoughts, tool names, and tool arguments to receive observations that guide our next steps. Our goal is to determine the validity of the claim by gathering and analyzing information from Wikipedia.\n",
      "\n",
      "2025/03/09 00:51:50 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "\n",
      "2025/03/09 00:51:50 INFO dspy.teleprompt.mipro_optimizer_v2: Proposed Instructions for Predictor 1:\n",
      "\n",
      "2025/03/09 00:51:50 INFO dspy.teleprompt.mipro_optimizer_v2: 0: Find all Wikipedia titles relevant to verifying (or refuting) the claim.\n",
      "\n",
      "2025/03/09 00:51:50 INFO dspy.teleprompt.mipro_optimizer_v2: 1: To verify the claim, please follow these steps: \n",
      "1. Identify the key elements of the claim, including names, events, and relationships.\n",
      "2. Search for relevant Wikipedia pages using the identified key elements.\n",
      "3. Analyze the search results to find information that supports or refutes the claim.\n",
      "4. Use the \"lookup_wikipedia\" tool to retrieve specific Wikipedia pages that may provide more detailed information.\n",
      "5. Evaluate the information found and determine whether it verifies or refutes the claim.\n",
      "6. Provide a reasoning for the conclusion, including the steps taken and the information found.\n",
      "7. List the relevant Wikipedia titles that support the conclusion.\n",
      "\n",
      "By following these steps, you should be able to verify or refute the claim and provide a clear explanation of the reasoning behind your conclusion.\n",
      "\n",
      "2025/03/09 00:51:50 INFO dspy.teleprompt.mipro_optimizer_v2: 2: To verify the given claim, please follow these steps: \n",
      "1. Identify the key elements of the claim, such as names, locations, and events.\n",
      "2. Use the search_wikipedia tool to find relevant Wikipedia pages related to these key elements.\n",
      "3. Analyze the search results to determine the accuracy of the claim.\n",
      "4. If necessary, use the lookup_wikipedia tool to retrieve specific information from relevant Wikipedia pages.\n",
      "5. Based on the information gathered, determine whether the claim is true or false.\n",
      "6. Provide a clear and concise reasoning statement explaining how you arrived at your conclusion.\n",
      "7. Include a list of relevant Wikipedia titles that support your conclusion.\n",
      "8. Use the finish tool to signal that you have completed the task and provide your final answer.\n",
      "\n",
      "Please ensure that your response is informative, descriptive, and follows the specified format.\n",
      "\n",
      "2025/03/09 00:51:50 INFO dspy.teleprompt.mipro_optimizer_v2: 3: To verify the given claim, we need to find all relevant Wikipedia titles that can either support or refute the statement. The claim is about a specific topic, and we want to gather information from Wikipedia to determine its accuracy. \n",
      "\n",
      "First, let's analyze the claim to identify key terms and concepts that we can use to search for relevant Wikipedia pages. We should look for specific names, locations, events, or other distinctive elements mentioned in the claim. \n",
      "\n",
      "Next, we will use the search tool to find Wikipedia pages related to these key terms. We may need to perform multiple searches, refining our query as we gather more information. \n",
      "\n",
      "As we search, we should keep track of the Wikipedia titles that seem most relevant to the claim. These titles may include pages about specific individuals, events, locations, or concepts mentioned in the claim. \n",
      "\n",
      "Once we have a list of relevant Wikipedia titles, we can use the lookup tool to read the content of these pages and gather more information. This will help us understand the context and details surrounding the claim. \n",
      "\n",
      "Finally, based on the information we've gathered, we can determine whether the claim is supported or refuted by the evidence from Wikipedia. We will provide a list of relevant Wikipedia titles that we used to verify or refute the claim.\n",
      "\n",
      "Please provide the claim you would like to verify, and we will begin the process of finding relevant Wikipedia titles and evaluating the evidence to support or refute the claim.\n",
      "\n",
      "2025/03/09 00:51:50 INFO dspy.teleprompt.mipro_optimizer_v2: 4: You are a fact-checker tasked with verifying the accuracy of claims. To do this, you will need to find all relevant Wikipedia titles that can help verify or refute the claim. Your goal is to provide a list of titles that are directly related to the claim, which will aid in determining its validity. Please use your knowledge of Wikipedia and its search functionality to identify the most pertinent titles.\n",
      "\n",
      "2025/03/09 00:51:50 INFO dspy.teleprompt.mipro_optimizer_v2: 5: You are a fact-checker for a prestigious news organization, and your task is to verify the claim \"The father of Zak Ové and A. Edward Sutherland are not both photographers.\" Failure to accurately verify this claim could lead to a loss of credibility for the organization and damage to your professional reputation. You have access to a vast database of information, including Wikipedia articles. Your goal is to find all relevant Wikipedia titles that can help you verify or refute the claim. You will need to use your research skills to identify the most relevant information and make a conclusion based on the evidence you find. The titles you provide will be used to support your conclusion, so it is crucial that you select the most accurate and relevant information.\n",
      "\n",
      "2025/03/09 00:51:50 INFO dspy.teleprompt.mipro_optimizer_v2: 6: To verify the given claim, start by analyzing the key entities and concepts mentioned in the claim. Then, use the search_wikipedia tool to find relevant Wikipedia pages that can help verify or refute the claim. Iterate through the search results, and for each relevant page, use the lookup_wikipedia tool to extract more information. Refine your search query as needed to find the most accurate information. Once you have gathered sufficient evidence, use the finish tool to conclude the task and provide the relevant Wikipedia titles.\n",
      "\n",
      "2025/03/09 00:51:50 INFO dspy.teleprompt.mipro_optimizer_v2: 7: To verify the claim, start by searching for key terms and phrases related to the claim on Wikipedia. Analyze the search results to identify relevant information, and then use this information to guide further searches or lookups on specific Wikipedia pages. As you gather more information, use your reasoning to determine the validity of the claim, and identify the most relevant Wikipedia titles that support or refute the claim. Be sure to consider multiple perspectives and evaluate the credibility of the information you find. Finally, provide a list of Wikipedia titles that are most relevant to verifying or refuting the claim, along with a clear explanation of your reasoning and thought process.\n",
      "\n",
      "2025/03/09 00:51:50 INFO dspy.teleprompt.mipro_optimizer_v2: 8: You are a fact-checker tasked with verifying claims related to various topics. Find all Wikipedia titles relevant to verifying (or refuting) the given claim by searching for information, analyzing the results, and drawing conclusions based on the evidence found. Provide a clear and step-by-step reasoning for your conclusions, and include the relevant Wikipedia titles in your final output.\n",
      "\n",
      "2025/03/09 00:51:50 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "\n",
      "2025/03/09 00:51:50 INFO dspy.teleprompt.mipro_optimizer_v2: ==> STEP 3: FINDING OPTIMAL PROMPT PARAMETERS <==\n",
      "2025/03/09 00:51:50 INFO dspy.teleprompt.mipro_optimizer_v2: We will evaluate the program over a series of trials with different combinations of instructions and few-shot examples to find the optimal combination using Bayesian Optimization.\n",
      "\n",
      "2025/03/09 00:51:50 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 1 / 28 - Full Evaluation of Default Program ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 35.33 / 80 (44.2%): 100%|██████████| 80/80 [02:01<00:00,  1.52s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/09 00:53:52 INFO dspy.evaluate.evaluate: Average Metric: 35.33333333333333 / 80 (44.2%)\n",
      "2025/03/09 00:53:52 INFO dspy.teleprompt.mipro_optimizer_v2: Default program score: 44.17\n",
      "\n",
      "2025/03/09 00:53:52 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 2 / 28 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 14.67 / 25 (58.7%): 100%|██████████| 25/25 [00:23<00:00,  1.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/09 00:54:15 INFO dspy.evaluate.evaluate: Average Metric: 14.666666666666666 / 25 (58.7%)\n",
      "2025/03/09 00:54:15 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 58.67 on minibatch of size 25 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 3', 'Predictor 1: Instruction 8', 'Predictor 1: Few-Shot Set 5'].\n",
      "2025/03/09 00:54:15 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [58.67]\n",
      "2025/03/09 00:54:15 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [44.17]\n",
      "2025/03/09 00:54:15 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 44.17\n",
      "2025/03/09 00:54:15 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
      "\n",
      "\n",
      "2025/03/09 00:54:15 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 3 / 28 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 12.67 / 25 (50.7%): 100%|██████████| 25/25 [00:25<00:00,  1.01s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/09 00:54:41 INFO dspy.evaluate.evaluate: Average Metric: 12.666666666666666 / 25 (50.7%)\n",
      "2025/03/09 00:54:41 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 50.67 on minibatch of size 25 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 3', 'Predictor 1: Instruction 8', 'Predictor 1: Few-Shot Set 1'].\n",
      "2025/03/09 00:54:41 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [58.67, 50.67]\n",
      "2025/03/09 00:54:41 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [44.17]\n",
      "2025/03/09 00:54:41 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 44.17\n",
      "2025/03/09 00:54:41 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
      "\n",
      "\n",
      "2025/03/09 00:54:41 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 4 / 28 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.67 / 25 (42.7%): 100%|██████████| 25/25 [00:29<00:00,  1.16s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/09 00:55:10 INFO dspy.evaluate.evaluate: Average Metric: 10.666666666666666 / 25 (42.7%)\n",
      "2025/03/09 00:55:10 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 42.67 on minibatch of size 25 with parameters ['Predictor 0: Instruction 8', 'Predictor 0: Few-Shot Set 2', 'Predictor 1: Instruction 8', 'Predictor 1: Few-Shot Set 3'].\n",
      "2025/03/09 00:55:10 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [58.67, 50.67, 42.67]\n",
      "2025/03/09 00:55:10 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [44.17]\n",
      "2025/03/09 00:55:10 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 44.17\n",
      "2025/03/09 00:55:10 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
      "\n",
      "\n",
      "2025/03/09 00:55:10 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 5 / 28 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 15.33 / 25 (61.3%): 100%|██████████| 25/25 [00:16<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/09 00:55:26 INFO dspy.evaluate.evaluate: Average Metric: 15.333333333333332 / 25 (61.3%)\n",
      "2025/03/09 00:55:26 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 61.33 on minibatch of size 25 with parameters ['Predictor 0: Instruction 5', 'Predictor 0: Few-Shot Set 4', 'Predictor 1: Instruction 3', 'Predictor 1: Few-Shot Set 0'].\n",
      "2025/03/09 00:55:26 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [58.67, 50.67, 42.67, 61.33]\n",
      "2025/03/09 00:55:26 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [44.17]\n",
      "2025/03/09 00:55:26 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 44.17\n",
      "2025/03/09 00:55:26 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
      "\n",
      "\n",
      "2025/03/09 00:55:26 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 6 / 28 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 15.67 / 25 (62.7%): 100%|██████████| 25/25 [00:15<00:00,  1.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/09 00:55:42 INFO dspy.evaluate.evaluate: Average Metric: 15.666666666666666 / 25 (62.7%)\n",
      "2025/03/09 00:55:42 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 62.67 on minibatch of size 25 with parameters ['Predictor 0: Instruction 3', 'Predictor 0: Few-Shot Set 7', 'Predictor 1: Instruction 0', 'Predictor 1: Few-Shot Set 6'].\n",
      "2025/03/09 00:55:42 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [58.67, 50.67, 42.67, 61.33, 62.67]\n",
      "2025/03/09 00:55:42 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [44.17]\n",
      "2025/03/09 00:55:42 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 44.17\n",
      "2025/03/09 00:55:42 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
      "\n",
      "\n",
      "2025/03/09 00:55:42 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 7 / 28 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 13.67 / 25 (54.7%): 100%|██████████| 25/25 [00:40<00:00,  1.63s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/09 00:56:23 INFO dspy.evaluate.evaluate: Average Metric: 13.666666666666666 / 25 (54.7%)\n",
      "2025/03/09 00:56:23 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 54.67 on minibatch of size 25 with parameters ['Predictor 0: Instruction 4', 'Predictor 0: Few-Shot Set 0', 'Predictor 1: Instruction 7', 'Predictor 1: Few-Shot Set 3'].\n",
      "2025/03/09 00:56:23 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [58.67, 50.67, 42.67, 61.33, 62.67, 54.67]\n",
      "2025/03/09 00:56:23 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [44.17]\n",
      "2025/03/09 00:56:23 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 44.17\n",
      "2025/03/09 00:56:23 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
      "\n",
      "\n",
      "2025/03/09 00:56:23 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 8 / 28 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 14.00 / 25 (56.0%): 100%|██████████| 25/25 [00:24<00:00,  1.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/09 00:56:48 INFO dspy.evaluate.evaluate: Average Metric: 14.0 / 25 (56.0%)\n",
      "2025/03/09 00:56:48 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 56.0 on minibatch of size 25 with parameters ['Predictor 0: Instruction 8', 'Predictor 0: Few-Shot Set 7', 'Predictor 1: Instruction 1', 'Predictor 1: Few-Shot Set 3'].\n",
      "2025/03/09 00:56:48 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [58.67, 50.67, 42.67, 61.33, 62.67, 54.67, 56.0]\n",
      "2025/03/09 00:56:48 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [44.17]\n",
      "2025/03/09 00:56:48 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 44.17\n",
      "2025/03/09 00:56:48 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
      "\n",
      "\n",
      "2025/03/09 00:56:48 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 9 / 28 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 14.67 / 25 (58.7%): 100%|██████████| 25/25 [00:29<00:00,  1.19s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/09 00:57:17 INFO dspy.evaluate.evaluate: Average Metric: 14.666666666666666 / 25 (58.7%)\n",
      "2025/03/09 00:57:17 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 58.67 on minibatch of size 25 with parameters ['Predictor 0: Instruction 7', 'Predictor 0: Few-Shot Set 3', 'Predictor 1: Instruction 7', 'Predictor 1: Few-Shot Set 0'].\n",
      "2025/03/09 00:57:17 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [58.67, 50.67, 42.67, 61.33, 62.67, 54.67, 56.0, 58.67]\n",
      "2025/03/09 00:57:17 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [44.17]\n",
      "2025/03/09 00:57:17 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 44.17\n",
      "2025/03/09 00:57:17 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
      "\n",
      "\n",
      "2025/03/09 00:57:17 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 10 / 28 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 16.33 / 25 (65.3%): 100%|██████████| 25/25 [00:17<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/09 00:57:35 INFO dspy.evaluate.evaluate: Average Metric: 16.333333333333332 / 25 (65.3%)\n",
      "2025/03/09 00:57:35 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 65.33 on minibatch of size 25 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 1', 'Predictor 1: Instruction 3', 'Predictor 1: Few-Shot Set 7'].\n",
      "2025/03/09 00:57:35 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [58.67, 50.67, 42.67, 61.33, 62.67, 54.67, 56.0, 58.67, 65.33]\n",
      "2025/03/09 00:57:35 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [44.17]\n",
      "2025/03/09 00:57:35 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 44.17\n",
      "2025/03/09 00:57:35 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/03/09 00:57:35 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 11 / 28 - Full Evaluation =====\n",
      "2025/03/09 00:57:35 INFO dspy.teleprompt.mipro_optimizer_v2: Doing full eval on next top averaging program (Avg Score: 65.33) from minibatch trials...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 49.67 / 80 (62.1%): 100%|██████████| 80/80 [00:39<00:00,  2.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/09 00:58:15 INFO dspy.evaluate.evaluate: Average Metric: 49.666666666666664 / 80 (62.1%)\n",
      "2025/03/09 00:58:15 INFO dspy.teleprompt.mipro_optimizer_v2: \u001b[92mNew best full eval score!\u001b[0m Score: 62.08\n",
      "2025/03/09 00:58:15 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [44.17, 62.08]\n",
      "2025/03/09 00:58:15 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 62.08\n",
      "2025/03/09 00:58:15 INFO dspy.teleprompt.mipro_optimizer_v2: =======================\n",
      "2025/03/09 00:58:15 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "\n",
      "2025/03/09 00:58:15 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 12 / 28 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 13.67 / 25 (54.7%): 100%|██████████| 25/25 [00:24<00:00,  1.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/09 00:58:40 INFO dspy.evaluate.evaluate: Average Metric: 13.666666666666666 / 25 (54.7%)\n",
      "2025/03/09 00:58:40 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 54.67 on minibatch of size 25 with parameters ['Predictor 0: Instruction 3', 'Predictor 0: Few-Shot Set 6', 'Predictor 1: Instruction 0', 'Predictor 1: Few-Shot Set 4'].\n",
      "2025/03/09 00:58:40 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [58.67, 50.67, 42.67, 61.33, 62.67, 54.67, 56.0, 58.67, 65.33, 54.67]\n",
      "2025/03/09 00:58:40 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [44.17, 62.08]\n",
      "2025/03/09 00:58:40 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 62.08\n",
      "2025/03/09 00:58:40 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/03/09 00:58:40 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 13 / 28 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 13.33 / 25 (53.3%): 100%|██████████| 25/25 [00:09<00:00,  2.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/09 00:58:49 INFO dspy.evaluate.evaluate: Average Metric: 13.333333333333332 / 25 (53.3%)\n",
      "2025/03/09 00:58:49 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 53.33 on minibatch of size 25 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 1', 'Predictor 1: Instruction 1', 'Predictor 1: Few-Shot Set 7'].\n",
      "2025/03/09 00:58:49 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [58.67, 50.67, 42.67, 61.33, 62.67, 54.67, 56.0, 58.67, 65.33, 54.67, 53.33]\n",
      "2025/03/09 00:58:49 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [44.17, 62.08]\n",
      "2025/03/09 00:58:49 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 62.08\n",
      "2025/03/09 00:58:49 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/03/09 00:58:49 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 14 / 28 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 11.67 / 25 (46.7%): 100%|██████████| 25/25 [00:19<00:00,  1.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/09 00:59:09 INFO dspy.evaluate.evaluate: Average Metric: 11.666666666666666 / 25 (46.7%)\n",
      "2025/03/09 00:59:09 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 46.67 on minibatch of size 25 with parameters ['Predictor 0: Instruction 3', 'Predictor 0: Few-Shot Set 5', 'Predictor 1: Instruction 0', 'Predictor 1: Few-Shot Set 6'].\n",
      "2025/03/09 00:59:09 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [58.67, 50.67, 42.67, 61.33, 62.67, 54.67, 56.0, 58.67, 65.33, 54.67, 53.33, 46.67]\n",
      "2025/03/09 00:59:09 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [44.17, 62.08]\n",
      "2025/03/09 00:59:09 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 62.08\n",
      "2025/03/09 00:59:09 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/03/09 00:59:09 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 15 / 28 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 15.67 / 25 (62.7%): 100%|██████████| 25/25 [00:19<00:00,  1.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/09 00:59:28 INFO dspy.evaluate.evaluate: Average Metric: 15.666666666666666 / 25 (62.7%)\n",
      "2025/03/09 00:59:28 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 62.67 on minibatch of size 25 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 1', 'Predictor 1: Instruction 3', 'Predictor 1: Few-Shot Set 7'].\n",
      "2025/03/09 00:59:28 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [58.67, 50.67, 42.67, 61.33, 62.67, 54.67, 56.0, 58.67, 65.33, 54.67, 53.33, 46.67, 62.67]\n",
      "2025/03/09 00:59:28 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [44.17, 62.08]\n",
      "2025/03/09 00:59:28 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 62.08\n",
      "2025/03/09 00:59:28 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/03/09 00:59:28 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 16 / 28 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 12.33 / 25 (49.3%): 100%|██████████| 25/25 [00:37<00:00,  1.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/09 01:00:06 INFO dspy.evaluate.evaluate: Average Metric: 12.333333333333332 / 25 (49.3%)\n",
      "2025/03/09 01:00:06 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 49.33 on minibatch of size 25 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 7', 'Predictor 1: Instruction 5', 'Predictor 1: Few-Shot Set 6'].\n",
      "2025/03/09 01:00:06 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [58.67, 50.67, 42.67, 61.33, 62.67, 54.67, 56.0, 58.67, 65.33, 54.67, 53.33, 46.67, 62.67, 49.33]\n",
      "2025/03/09 01:00:06 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [44.17, 62.08]\n",
      "2025/03/09 01:00:06 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 62.08\n",
      "2025/03/09 01:00:06 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/03/09 01:00:06 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 17 / 28 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 14.67 / 25 (58.7%): 100%|██████████| 25/25 [00:24<00:00,  1.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/09 01:00:30 INFO dspy.evaluate.evaluate: Average Metric: 14.666666666666666 / 25 (58.7%)\n",
      "2025/03/09 01:00:30 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 58.67 on minibatch of size 25 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 4', 'Predictor 1: Instruction 3', 'Predictor 1: Few-Shot Set 7'].\n",
      "2025/03/09 01:00:30 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [58.67, 50.67, 42.67, 61.33, 62.67, 54.67, 56.0, 58.67, 65.33, 54.67, 53.33, 46.67, 62.67, 49.33, 58.67]\n",
      "2025/03/09 01:00:30 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [44.17, 62.08]\n",
      "2025/03/09 01:00:30 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 62.08\n",
      "2025/03/09 01:00:30 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/03/09 01:00:30 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 18 / 28 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 16.33 / 25 (65.3%): 100%|██████████| 25/25 [00:03<00:00,  6.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/09 01:00:34 INFO dspy.evaluate.evaluate: Average Metric: 16.333333333333332 / 25 (65.3%)\n",
      "2025/03/09 01:00:34 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 65.33 on minibatch of size 25 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 1', 'Predictor 1: Instruction 3', 'Predictor 1: Few-Shot Set 5'].\n",
      "2025/03/09 01:00:34 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [58.67, 50.67, 42.67, 61.33, 62.67, 54.67, 56.0, 58.67, 65.33, 54.67, 53.33, 46.67, 62.67, 49.33, 58.67, 65.33]\n",
      "2025/03/09 01:00:34 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [44.17, 62.08]\n",
      "2025/03/09 01:00:34 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 62.08\n",
      "2025/03/09 01:00:34 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/03/09 01:00:34 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 19 / 28 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 11.33 / 25 (45.3%): 100%|██████████| 25/25 [00:25<00:00,  1.00s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/09 01:00:59 INFO dspy.evaluate.evaluate: Average Metric: 11.333333333333332 / 25 (45.3%)\n",
      "2025/03/09 01:00:59 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 45.33 on minibatch of size 25 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 6', 'Predictor 1: Instruction 6', 'Predictor 1: Few-Shot Set 5'].\n",
      "2025/03/09 01:00:59 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [58.67, 50.67, 42.67, 61.33, 62.67, 54.67, 56.0, 58.67, 65.33, 54.67, 53.33, 46.67, 62.67, 49.33, 58.67, 65.33, 45.33]\n",
      "2025/03/09 01:00:59 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [44.17, 62.08]\n",
      "2025/03/09 01:00:59 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 62.08\n",
      "2025/03/09 01:00:59 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/03/09 01:00:59 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 20 / 28 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.67 / 16 (54.2%):  64%|██████▍   | 16/25 [00:10<00:03,  2.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/09 01:01:11 ERROR dspy.utils.parallelizer: Error processing item Example({'claim': 'Grand Forks International Airport is closer to the town it is near, than the airport close by to The Texas Air & Space Museum.', 'titles': ['Rick Husband Amarillo International Airport', 'Grand Forks International Airport', 'Texas Air &amp; Space Museum']}) (input_keys={'claim'}): 1 validation error for literal['search_wikipedia','lookup_wikipedia','finish']\n",
      "  Input should be 'search_wikipedia', 'lookup_wikipedia' or 'finish' [type=literal_error, input_value='modify_tool', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/literal_error. Set `provide_traceback=True` to see the stack trace.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.33 / 24 (55.6%): 100%|██████████| 25/25 [00:14<00:00,  1.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/09 01:01:14 INFO dspy.evaluate.evaluate: Average Metric: 13.333333333333332 / 25 (53.3%)\n",
      "2025/03/09 01:01:14 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 53.33 on minibatch of size 25 with parameters ['Predictor 0: Instruction 6', 'Predictor 0: Few-Shot Set 8', 'Predictor 1: Instruction 3', 'Predictor 1: Few-Shot Set 5'].\n",
      "2025/03/09 01:01:14 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [58.67, 50.67, 42.67, 61.33, 62.67, 54.67, 56.0, 58.67, 65.33, 54.67, 53.33, 46.67, 62.67, 49.33, 58.67, 65.33, 45.33, 53.33]\n",
      "2025/03/09 01:01:14 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [44.17, 62.08]\n",
      "2025/03/09 01:01:14 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 62.08\n",
      "2025/03/09 01:01:14 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/03/09 01:01:14 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 21 / 28 - Full Evaluation =====\n",
      "2025/03/09 01:01:14 INFO dspy.teleprompt.mipro_optimizer_v2: Doing full eval on next top averaging program (Avg Score: 65.33) from minibatch trials...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 46.67 / 80 (58.3%): 100%|██████████| 80/80 [00:06<00:00, 12.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/09 01:01:21 INFO dspy.evaluate.evaluate: Average Metric: 46.666666666666664 / 80 (58.3%)\n",
      "2025/03/09 01:01:21 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [44.17, 62.08, 58.33]\n",
      "2025/03/09 01:01:21 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 62.08\n",
      "2025/03/09 01:01:21 INFO dspy.teleprompt.mipro_optimizer_v2: =======================\n",
      "2025/03/09 01:01:21 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "\n",
      "2025/03/09 01:01:21 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 22 / 28 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 16.00 / 25 (64.0%): 100%|██████████| 25/25 [00:20<00:00,  1.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/09 01:01:42 INFO dspy.evaluate.evaluate: Average Metric: 16.0 / 25 (64.0%)\n",
      "2025/03/09 01:01:42 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 64.0 on minibatch of size 25 with parameters ['Predictor 0: Instruction 7', 'Predictor 0: Few-Shot Set 7', 'Predictor 1: Instruction 0', 'Predictor 1: Few-Shot Set 1'].\n",
      "2025/03/09 01:01:42 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [58.67, 50.67, 42.67, 61.33, 62.67, 54.67, 56.0, 58.67, 65.33, 54.67, 53.33, 46.67, 62.67, 49.33, 58.67, 65.33, 45.33, 53.33, 64.0]\n",
      "2025/03/09 01:01:42 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [44.17, 62.08, 58.33]\n",
      "2025/03/09 01:01:42 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 62.08\n",
      "2025/03/09 01:01:42 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/03/09 01:01:42 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 23 / 28 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 16.67 / 25 (66.7%): 100%|██████████| 25/25 [00:17<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/09 01:02:00 INFO dspy.evaluate.evaluate: Average Metric: 16.666666666666668 / 25 (66.7%)\n",
      "2025/03/09 01:02:00 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 66.67 on minibatch of size 25 with parameters ['Predictor 0: Instruction 7', 'Predictor 0: Few-Shot Set 7', 'Predictor 1: Instruction 4', 'Predictor 1: Few-Shot Set 7'].\n",
      "2025/03/09 01:02:00 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [58.67, 50.67, 42.67, 61.33, 62.67, 54.67, 56.0, 58.67, 65.33, 54.67, 53.33, 46.67, 62.67, 49.33, 58.67, 65.33, 45.33, 53.33, 64.0, 66.67]\n",
      "2025/03/09 01:02:00 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [44.17, 62.08, 58.33]\n",
      "2025/03/09 01:02:00 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 62.08\n",
      "2025/03/09 01:02:00 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/03/09 01:02:00 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 24 / 28 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 16.33 / 25 (65.3%): 100%|██████████| 25/25 [00:14<00:00,  1.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/09 01:02:15 INFO dspy.evaluate.evaluate: Average Metric: 16.333333333333332 / 25 (65.3%)\n",
      "2025/03/09 01:02:15 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 65.33 on minibatch of size 25 with parameters ['Predictor 0: Instruction 7', 'Predictor 0: Few-Shot Set 1', 'Predictor 1: Instruction 4', 'Predictor 1: Few-Shot Set 7'].\n",
      "2025/03/09 01:02:15 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [58.67, 50.67, 42.67, 61.33, 62.67, 54.67, 56.0, 58.67, 65.33, 54.67, 53.33, 46.67, 62.67, 49.33, 58.67, 65.33, 45.33, 53.33, 64.0, 66.67, 65.33]\n",
      "2025/03/09 01:02:15 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [44.17, 62.08, 58.33]\n",
      "2025/03/09 01:02:15 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 62.08\n",
      "2025/03/09 01:02:15 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/03/09 01:02:15 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 25 / 28 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 17.00 / 25 (68.0%): 100%|██████████| 25/25 [00:15<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/09 01:02:31 INFO dspy.evaluate.evaluate: Average Metric: 17.0 / 25 (68.0%)\n",
      "2025/03/09 01:02:31 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 68.0 on minibatch of size 25 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 7', 'Predictor 1: Instruction 4', 'Predictor 1: Few-Shot Set 7'].\n",
      "2025/03/09 01:02:31 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [58.67, 50.67, 42.67, 61.33, 62.67, 54.67, 56.0, 58.67, 65.33, 54.67, 53.33, 46.67, 62.67, 49.33, 58.67, 65.33, 45.33, 53.33, 64.0, 66.67, 65.33, 68.0]\n",
      "2025/03/09 01:02:31 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [44.17, 62.08, 58.33]\n",
      "2025/03/09 01:02:31 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 62.08\n",
      "2025/03/09 01:02:31 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/03/09 01:02:31 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 26 / 28 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 18.33 / 25 (73.3%): 100%|██████████| 25/25 [00:15<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/09 01:02:47 INFO dspy.evaluate.evaluate: Average Metric: 18.333333333333332 / 25 (73.3%)\n",
      "2025/03/09 01:02:47 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 73.33 on minibatch of size 25 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 7', 'Predictor 1: Instruction 4', 'Predictor 1: Few-Shot Set 7'].\n",
      "2025/03/09 01:02:47 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [58.67, 50.67, 42.67, 61.33, 62.67, 54.67, 56.0, 58.67, 65.33, 54.67, 53.33, 46.67, 62.67, 49.33, 58.67, 65.33, 45.33, 53.33, 64.0, 66.67, 65.33, 68.0, 73.33]\n",
      "2025/03/09 01:02:47 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [44.17, 62.08, 58.33]\n",
      "2025/03/09 01:02:47 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 62.08\n",
      "2025/03/09 01:02:47 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/03/09 01:02:47 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 27 / 28 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 17.33 / 25 (69.3%): 100%|██████████| 25/25 [00:26<00:00,  1.07s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/09 01:03:14 INFO dspy.evaluate.evaluate: Average Metric: 17.333333333333332 / 25 (69.3%)\n",
      "2025/03/09 01:03:14 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 69.33 on minibatch of size 25 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 0', 'Predictor 1: Instruction 4', 'Predictor 1: Few-Shot Set 7'].\n",
      "2025/03/09 01:03:14 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [58.67, 50.67, 42.67, 61.33, 62.67, 54.67, 56.0, 58.67, 65.33, 54.67, 53.33, 46.67, 62.67, 49.33, 58.67, 65.33, 45.33, 53.33, 64.0, 66.67, 65.33, 68.0, 73.33, 69.33]\n",
      "2025/03/09 01:03:14 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [44.17, 62.08, 58.33]\n",
      "2025/03/09 01:03:14 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 62.08\n",
      "2025/03/09 01:03:14 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/03/09 01:03:14 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 28 / 28 - Full Evaluation =====\n",
      "2025/03/09 01:03:14 INFO dspy.teleprompt.mipro_optimizer_v2: Doing full eval on next top averaging program (Avg Score: 70.66499999999999) from minibatch trials...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 51.00 / 80 (63.8%): 100%|██████████| 80/80 [00:18<00:00,  4.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/09 01:03:33 INFO dspy.evaluate.evaluate: Average Metric: 51.0 / 80 (63.8%)\n",
      "2025/03/09 01:03:33 INFO dspy.teleprompt.mipro_optimizer_v2: \u001b[92mNew best full eval score!\u001b[0m Score: 63.75\n",
      "2025/03/09 01:03:33 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [44.17, 62.08, 58.33, 63.75]\n",
      "2025/03/09 01:03:33 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 63.75\n",
      "2025/03/09 01:03:33 INFO dspy.teleprompt.mipro_optimizer_v2: =======================\n",
      "2025/03/09 01:03:33 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "\n",
      "2025/03/09 01:03:33 INFO dspy.teleprompt.mipro_optimizer_v2: Returning best identified program with score 63.75!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "llama3_70b = dspy.LM('together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo', api_key=TOGETHER_API_KEY, api_base='https://api.together.xyz/v1', temperature=0.7)\n",
    "\n",
    "kwargs = dict(teacher_settings=dict(lm=llama3_70b), prompt_model=llama3_70b, max_errors=999)\n",
    "\n",
    "tp = dspy.MIPROv2(metric=top5_recall, auto=\"medium\", num_threads=16, **kwargs)\n",
    "\n",
    "optimized_react = tp.compile(react, trainset=trainset, max_bootstrapped_demos=3, max_labeled_demos=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 68.33 / 100 (68.3%): 100%|██████████| 100/100 [00:44<00:00,  2.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/09 01:05:56 INFO dspy.evaluate.evaluate: Average Metric: 68.33333333333333 / 100 (68.3%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim</th>\n",
       "      <th>example_titles</th>\n",
       "      <th>trajectory</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>pred_titles</th>\n",
       "      <th>top5_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Church of England's movement that inspired the Trinity Episcop...</td>\n",
       "      <td>[Samuel Rickards, Trinity Episcopal Church (Houghton, Michigan), O...</td>\n",
       "      <td>{'thought_0': 'To verify the claim, we need to find the movement t...</td>\n",
       "      <td>The claim states that the Church of England's movement that inspir...</td>\n",
       "      <td>[Oxford Movement, Samuel Rickards, Trinity Episcopal Church (Hough...</td>\n",
       "      <td>✔️ [1.000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Red, White &amp; Crüe and this athlete both fight. The french fighter ...</td>\n",
       "      <td>[Bobby Stewart, Red, White &amp;amp; Crüe, Mike Tyson]</td>\n",
       "      <td>{'thought_0': 'The claim mentions two entities that fight: Red, Wh...</td>\n",
       "      <td>The claim states that a director known for his work on Miss Potter...</td>\n",
       "      <td>[Chris Noonan, Babe (film), Miss Potter, Academy Award for Best Di...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The writer/director/actor from Glen or Glenda and Fernand Rivers s...</td>\n",
       "      <td>[Glen or Glenda, Fernand Rivers, Ed Wood]</td>\n",
       "      <td>{'thought_0': 'To verify the claim, we need to find the writer/dir...</td>\n",
       "      <td>The claim states that the writer/director/actor from Glen or Glend...</td>\n",
       "      <td>[Ed Wood, Fernand Rivers, Glen or Glenda, Fernand Rivers (film dir...</td>\n",
       "      <td>✔️ [1.000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The film by Sandi Sissel was released before The End of Suburbia.</td>\n",
       "      <td>[Chicken Ranch (film), The End of Suburbia, Sandi Sissel]</td>\n",
       "      <td>{'thought_0': 'We need to find the film by Sandi Sissel and compar...</td>\n",
       "      <td>The claim states that the film by Sandi Sissel was released before...</td>\n",
       "      <td>[Chicken Ranch, The End of Suburbia, Sandi Sissel]</td>\n",
       "      <td>✔️ [0.667]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The actor who played captain hook in the live production with Tayl...</td>\n",
       "      <td>[Taylor Louderman, Christopher Walken, Peter Pan Live!]</td>\n",
       "      <td>{'thought_0': 'To verify the claim, we need to find the actor who ...</td>\n",
       "      <td>The claim states that the actor who played captain hook in the liv...</td>\n",
       "      <td>[Christopher Walken, The Deer Hunter, Taylor Louderman, Peter Pan ...</td>\n",
       "      <td>✔️ [1.000]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   claim  \\\n",
       "0  The Church of England's movement that inspired the Trinity Episcop...   \n",
       "1  Red, White & Crüe and this athlete both fight. The french fighter ...   \n",
       "2  The writer/director/actor from Glen or Glenda and Fernand Rivers s...   \n",
       "3      The film by Sandi Sissel was released before The End of Suburbia.   \n",
       "4  The actor who played captain hook in the live production with Tayl...   \n",
       "\n",
       "                                                          example_titles  \\\n",
       "0  [Samuel Rickards, Trinity Episcopal Church (Houghton, Michigan), O...   \n",
       "1                     [Bobby Stewart, Red, White &amp; Crüe, Mike Tyson]   \n",
       "2                              [Glen or Glenda, Fernand Rivers, Ed Wood]   \n",
       "3              [Chicken Ranch (film), The End of Suburbia, Sandi Sissel]   \n",
       "4                [Taylor Louderman, Christopher Walken, Peter Pan Live!]   \n",
       "\n",
       "                                                              trajectory  \\\n",
       "0  {'thought_0': 'To verify the claim, we need to find the movement t...   \n",
       "1  {'thought_0': 'The claim mentions two entities that fight: Red, Wh...   \n",
       "2  {'thought_0': 'To verify the claim, we need to find the writer/dir...   \n",
       "3  {'thought_0': 'We need to find the film by Sandi Sissel and compar...   \n",
       "4  {'thought_0': 'To verify the claim, we need to find the actor who ...   \n",
       "\n",
       "                                                               reasoning  \\\n",
       "0  The claim states that the Church of England's movement that inspir...   \n",
       "1  The claim states that a director known for his work on Miss Potter...   \n",
       "2  The claim states that the writer/director/actor from Glen or Glend...   \n",
       "3  The claim states that the film by Sandi Sissel was released before...   \n",
       "4  The claim states that the actor who played captain hook in the liv...   \n",
       "\n",
       "                                                             pred_titles  \\\n",
       "0  [Oxford Movement, Samuel Rickards, Trinity Episcopal Church (Hough...   \n",
       "1  [Chris Noonan, Babe (film), Miss Potter, Academy Award for Best Di...   \n",
       "2  [Ed Wood, Fernand Rivers, Glen or Glenda, Fernand Rivers (film dir...   \n",
       "3                     [Chicken Ranch, The End of Suburbia, Sandi Sissel]   \n",
       "4  [Christopher Walken, The Deer Hunter, Taylor Louderman, Peter Pan ...   \n",
       "\n",
       "  top5_recall  \n",
       "0  ✔️ [1.000]  \n",
       "1              \n",
       "2  ✔️ [1.000]  \n",
       "3  ✔️ [0.667]  \n",
       "4  ✔️ [1.000]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div style='\n",
       "                    text-align: center;\n",
       "                    font-size: 16px;\n",
       "                    font-weight: bold;\n",
       "                    color: #555;\n",
       "                    margin: 10px 0;'>\n",
       "                    ... 95 more rows not displayed ...\n",
       "                </div>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "68.33"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(optimized_react)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that MIPRO optimization significantly improved performance from around 49% recall to 68% recall.\n",
    "\n",
    "To understand how MIPRO achieved this improvement, let's examine the optimized prompts it generated. We'll run an example query and then use inspect_history() to see the prompts for both components of our ReAct agent - the reasoning loop that breaks down the task, and the final prediction module that produces the output titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Joe Orton',\n",
       " 'Bernard-Marie Koltès',\n",
       " 'Up Against It',\n",
       " 'The Beatles',\n",
       " 'Playwrights']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimized_react(claim=\"The author of the 1960s unproduced script written for The Beatles, Up Against It, and Bernard-Marie Koltès are both playwrights.\").titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-03-09T01:06:24.362989]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `claim` (str)\n",
      "2. `trajectory` (str)\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `titles` (list[str])\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## claim ## ]]\n",
      "{claim}\n",
      "\n",
      "[[ ## trajectory ## ]]\n",
      "{trajectory}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## titles ## ]]\n",
      "{titles}        # note: the value you produce must adhere to the JSON schema: {\"type\": \"array\", \"items\": {\"type\": \"string\"}}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        You are a fact-checker tasked with verifying the accuracy of claims. To do this, you will need to find all relevant Wikipedia titles that can help verify or refute the claim. Your goal is to provide a list of titles that are directly related to the claim, which will aid in determining its validity. Please use your knowledge of Wikipedia and its search functionality to identify the most pertinent titles.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## claim ## ]]\n",
      "This director is known for his work on Miss Potter. The Academy of Motion Picture Arts and Sciences presents the award in which he was nominated for his work in \"Babe\".\n",
      "\n",
      "[[ ## trajectory ## ]]\n",
      "[[ ## thought_0 ## ]]\n",
      "To verify the claim, we need to find the director known for his work on Miss Potter and check if he was nominated for an award by the Academy of Motion Picture Arts and Sciences for his work in \"Babe\". We can start by searching for the director of Miss Potter on Wikipedia.\n",
      "\n",
      "[[ ## tool_name_0 ## ]]\n",
      "search_wikipedia\n",
      "\n",
      "[[ ## tool_args_0 ## ]]\n",
      "{\"query\": \"Miss Potter director\"}\n",
      "\n",
      "[[ ## observation_0 ## ]]\n",
      "[1] «Miss Potter | Miss Potter is a 2006 Anglo-American biographical fiction family drama film directed by Chris Noonan. It is a biographical film of children's author and illustrator Beatrix Potter, and combines stories from her own life with animated sequences featuring characters from her stories, such as Peter Rabbit. Scripted by Richard Maltby, Jr., the director of the Tony-winning Broadway revue, \"Fosse\", the film stars Renée Zellweger in the title role; Ewan McGregor as her publisher and fiancé, Norman Warne; and Lloyd Owen as solicitor William Heelis. Emily Watson stars as Warne's sister, Millie. Lucy Boynton also stars as the young Beatrix Potter. It was filmed in St. Peter's Square Hammersmith, Cecil Court, Osterley Park, Covent Garden, the Isle of Man, Scotland and the Lake District. \"Miss Potter\" was released on 29 December 2006 so that the film could compete for the 2007 Academy Awards. The film was intended to be released generally on 12 January 2007, but Variety.com reported that the Weinstein Company had decided to push a wider release date until after the Academy Awards on 25 February 2007. The date seemed to fluctuate a number of times, but the Weinstein Company website ultimately listed its release date as 9 March. The film received generally positive reviews and earned Zellweger her sixth Golden Globe nomination.»\n",
      "[2] «Sally Potter | Charlotte Sally Potter, OBE (born 19 September 1949) is an English film director and screenwriter.»\n",
      "[3] «The Story of Miss Moppet | The Story of Miss Moppet is a tale about teasing, featuring a kitten and a mouse, that was written and illustrated by Beatrix Potter. It was published by Frederick Warne & Co for the 1906 Christmas season. Potter was born in London in 1866, and between 1902 and 1905 published a series of small format children's books with Warne. In 1906, she experimented with an atypical panorama design for \"Miss Moppet\", which booksellers disliked; the story was reprinted in 1916 in small book format.»\n",
      "[4] «H. C. Potter | Henry Codman Potter (sometimes II or Jr; November 13, 1904 – August 31, 1977) was an American theatrical producer and director and film director.»\n",
      "[5] «Julia Galloway | Julia Galloway is a potter who creates utilitarian work, and is a professor and Director of the School of Art at the University of Montana-Missoula.»\n",
      "[6] «Other retrieved pages have titles: `Melissa Potter`, `Madeleine Potter`, `Gerald Potterton`, `Fiona Weir`, `The Tales of Beatrix Potter`, `Bill Hays (director)`, `Chanida Phaengdara Potter`, `The Potters (film)`, `Bonnie Wright`, `Pottersville (film)`, `Miss Granny`, `Chris Columbus (filmmaker)`, `Homan Potterton`, `At the Potter's Wheel`, `Jacinta John`, `Potter's Clay`, `William C. Potter`, `Bärbel Wartenberg-Potter`, `Private Potter`, `Stephen Woolfenden`, `Fiona Shaw`, `Primrose Potter`, `The Party (2017 film)`, `The Girl in the Café`, `Tracy Potter`.»\n",
      "\n",
      "[[ ## thought_1 ## ]]\n",
      "The search results indicate that the director of the film \"Miss Potter\" is Chris Noonan. Now, we need to check if Chris Noonan was nominated for an award by the Academy of Motion Picture Arts and Sciences for his work in \"Babe\".\n",
      "\n",
      "[[ ## tool_name_1 ## ]]\n",
      "search_wikipedia\n",
      "\n",
      "[[ ## tool_args_1 ## ]]\n",
      "{\"query\": \"Chris Noonan Babe nomination\"}\n",
      "\n",
      "[[ ## observation_1 ## ]]\n",
      "[1] «Chris Noonan | Chris Noonan (born 14 November 1952) is a Sydney-based Australian filmmaker and actor best known for the family film \"Babe\" (1995), for which he was nominated for both the Academy Award for Best Director and Academy Award for Best Adapted Screenplay.»\n",
      "[2] «Babe (film) | Babe is a 1995 Australian-American comedy-drama film directed by Chris Noonan, produced by George Miller, and written by both. It is an adaptation of Dick King-Smith's 1983 novel \"The Sheep-Pig\", also known as \"Babe: The Gallant Pig\" in the US, which tells the story of a pig who wants to be a sheepdog. The main animal characters are played by a combination of real and animatronic pigs and Border Collies.»\n",
      "[3] «Chris Noonan (ice hockey) | Chris Noonan (born September 22, 1988) is an American ice hockey goaltender.»\n",
      "[4] «Chris Noonan (disambiguation) | Chris Noonan (born 1952) is an Australian filmmaker.»\n",
      "[5] «Chris Noonan (academic) | Chris Noonan is a New Zealand legal academic in trade, competition and company law at the University of Auckland. He was appointed the first Chief Trade Adviser to the Pacific Islands Forum in 2009, and resigned from that position on September 2011 and was succeeded by Edwini Kessie, a legal practitioner. He has a PhD and LLB from the University of Auckland.»\n",
      "[6] «Other retrieved pages have titles: `Michael Noonan (filmmaker)`, `Michael O'Keefe`, `The Wife (1995 film)`, `Miss Potter`, `Sinéad Noonan`, `Wade Noonan`, `Nick Noonan`, `Read my lips: no new taxes`, `Songs of the Latin Skies`, `Vietnam (miniseries)`, `Daniel Noonan`, `Karl Noonan`, `Danny Noonan (American football)`, `Thomas P. Noonan Jr.`, `Michael Noonan`, `Nathan Gamble`, `Danny Noonan (Australian footballer)`, `Brian Noonan`, `Edward C. Noonan`, `Rick Noonan`, `Tom Noonan`, `I Told You So (Karmin song)`, `Pat Noonan`, `Jay Friedkin`, `Chris Joseph (writer/artist)`.»\n",
      "\n",
      "[[ ## thought_2 ## ]]\n",
      "We have found that Chris Noonan was the director of \"Miss Potter\" and was nominated for an award by the Academy of Motion Picture Arts and Sciences for his work in \"Babe\". To verify the claim, we need to confirm that the award nomination was for the film \"Babe\". We can do this by looking up the Wikipedia page for Chris Noonan and checking the awards and nominations section.\n",
      "\n",
      "[[ ## tool_name_2 ## ]]\n",
      "lookup_wikipedia\n",
      "\n",
      "[[ ## tool_args_2 ## ]]\n",
      "{\"title\": \"Chris Noonan\"}\n",
      "\n",
      "[[ ## observation_2 ## ]]\n",
      "Chris Noonan (born 14 November 1952) is a Sydney-based Australian filmmaker and actor best known for the family film \"Babe\" (1995), for which he was nominated for both the Academy Award for Best Director and Academy Award for Best Adapted Screenplay.\n",
      "\n",
      "[[ ## thought_3 ## ]]\n",
      "We have verified the claim by finding the director of \"Miss Potter\" and checking if he was nominated for an award by the Academy of Motion Picture Arts and Sciences for his work in \"Babe\". The director, Chris Noonan, was indeed nominated for the Academy Award for Best Director and Academy Award for Best Adapted Screenplay for the film \"Babe\". We can now conclude that the claim is true.\n",
      "\n",
      "[[ ## tool_name_3 ## ]]\n",
      "finish\n",
      "\n",
      "[[ ## tool_args_3 ## ]]\n",
      "{\"titles\": [\"Chris Noonan\", \"Babe (film)\", \"Miss Potter\"]}\n",
      "\n",
      "[[ ## observation_3 ## ]]\n",
      "Failed to execute: Arg titles is not in the tool's args.\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## titles ## ]]` (must be formatted as a valid Python list[str]), and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The claim states that a director known for his work on Miss Potter was nominated for an award by the Academy of Motion Picture Arts and Sciences for his work in \"Babe\". We first searched for the director of Miss Potter and found that it was Chris Noonan. Then, we checked if Chris Noonan was nominated for an award for his work in \"Babe\" and found that he was nominated for the Academy Award for Best Director and Academy Award for Best Adapted Screenplay. This verifies the claim.\n",
      "\n",
      "[[ ## titles ## ]]\n",
      "[\"Chris Noonan\", \"Babe (film)\", \"Miss Potter\", \"Academy Award for Best Director\", \"Academy Award for Best Adapted Screenplay\"]\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## claim ## ]]\n",
      "The author of the 1960s unproduced script written for The Beatles, Up Against It, and Bernard-Marie Koltès are both playwrights.\n",
      "\n",
      "[[ ## trajectory ## ]]\n",
      "[[ ## thought_0 ## ]]\n",
      "To verify the claim, we need to find information about the author of the 1960s unproduced script written for The Beatles, Up Against It, and Bernard-Marie Koltès. We can start by searching for the author of the script on Wikipedia.\n",
      "\n",
      "[[ ## tool_name_0 ## ]]\n",
      "search_wikipedia\n",
      "\n",
      "[[ ## tool_args_0 ## ]]\n",
      "{\"query\": \"Up Against It script author\"}\n",
      "\n",
      "[[ ## observation_0 ## ]]\n",
      "[1] «Up Against It | Up Against It is an unproduced script by Joe Orton, written in 1967 for The Beatles at the height of their fame.»\n",
      "[2] «Up Against It! (Todd Rundgren album) | Up Against It! is a 1997 album by Todd Rundgren, essentially consisting of Rundgren's song demos for the Off Broadway show that were Written and Recorded by Todd from 1986-88. The project was inspired by the never-produced Up Against It which was a play originally written by Joe Orton for The Beatles.»\n",
      "[3] «Against All Things Ending | Against All Things Ending is a 2010 fantasy novel by American writer Stephen R. Donaldson. It is the third novel in the \"Last Chronicles of Thomas Covenant\" tetralogy, and the ninth novel in \"The Chronicles of Thomas Covenant\" overall. It was released on October 19, 2010 in the USA and on 28 October 2010 in the United Kingdom.»\n",
      "[4] «Five Against Venus | Five Against Venus, written by Philip Latham, is a science-fiction novel first published in the United States in 1952 by the John C. Winston Company. Philip Latham was the nom de plume of Robert S. Richardson, a professional astronomer who also provided technical assistance on movies such as \"Destination Moon\" and wrote scripts for the \"Captain Video\" television series.»\n",
      "[5] «Against the Odds (novel) | Against the Odds is a science fiction novel by Elizabeth Moon. It is her seventh and last novel set in the Familias Regnant fictional universe. It does not fall in either informal trilogy (the Heris Serrano and the Esmay Suiza trilogies); fittingly it does not focus on any particular character, instead a more general, almost kaleidoscopic perspective of the upheaval in the Familias Regnant, and the rise to power of a new and more capable Speaker. It can be seen as a conclusion to the series, resolving or at least making a good start at resolving many issues and peoples and ending as it does on a memorializing elegiac note.»\n",
      "[6] «Other retrieved pages have titles: `Up Against It (1912 film)`, `Against a Dark Background`, `Thirteen Against Fate`, `Against the Fall of Night`, `Against the Day (1999)`, `The War Against the Assholes`, `William P. McGivern`, `Against the Day`, `Seventeen Against the Dealer`, `Something Against You (Grey's Anatomy)`, `Against the Norm`, `Mark Greif`, `Up Against It (album)`, `Odds Against Tomorrow`, `Hollywood, Interrupted`, `Not For, or Against`, `H. P. Lovecraft: Against the World, Against Life`, `Against Happiness`, `The Opposing Shore`, `Iqbal Mohammed`, `The Plot Against America`, `Against All Enemies (novel)`, `Bows against the Barons`, `The Man Who Wouldn't Stand Up`, `Fredy Perlman`.»\n",
      "\n",
      "[[ ## thought_1 ## ]]\n",
      "We have found that the author of the 1960s unproduced script written for The Beatles, Up Against It, is Joe Orton. Next, we need to verify that Joe Orton is indeed a playwright. We can do this by checking the Wikipedia page for Joe Orton and confirming his profession.\n",
      "\n",
      "[[ ## tool_name_1 ## ]]\n",
      "lookup_wikipedia\n",
      "\n",
      "[[ ## tool_args_1 ## ]]\n",
      "{\"title\": \"Joe Orton\"}\n",
      "\n",
      "[[ ## observation_1 ## ]]\n",
      "John Kingsley \"Joe\" Orton (1 January 1933 – 9 August 1967) was an English playwright and author. His public career was short but prolific, lasting from 1964 until his death three years later. During this brief period he shocked, outraged, and amused audiences with his scandalous black comedies. The adjective \"Ortonesque\" is sometimes used to refer to work characterised by a similarly dark yet farcical cynicism.\n",
      "\n",
      "[[ ## thought_2 ## ]]\n",
      "We have verified that Joe Orton is indeed a playwright, as he was an English playwright and author. Now, we need to verify that Bernard-Marie Koltès is also a playwright. We can do this by checking the Wikipedia page for Bernard-Marie Koltès and confirming his profession.\n",
      "\n",
      "[[ ## tool_name_2 ## ]]\n",
      "lookup_wikipedia\n",
      "\n",
      "[[ ## tool_args_2 ## ]]\n",
      "{\"title\": \"Bernard-Marie Koltès\"}\n",
      "\n",
      "[[ ## observation_2 ## ]]\n",
      "Bernard-Marie Koltès (] ; 9 April 1948 – 15 April 1989) was a French playwright and theatre director best known for his plays \"La Nuit juste avant les Forêts\" (\"The Night Just Before the Forests\", 1976), \"Sallinger\" (1977) and \"Dans la Solitude des Champs de Coton\" (\"In the Solitude of Cotton Fields\", 1986).\n",
      "\n",
      "[[ ## thought_3 ## ]]\n",
      "We have verified the claim that Joe Orton and Bernard-Marie Koltès are both playwrights. Now, we can conclude that the claim is true.\n",
      "\n",
      "[[ ## tool_name_3 ## ]]\n",
      "finish\n",
      "\n",
      "[[ ## tool_args_3 ## ]]\n",
      "{\"titles\": [\"Joe Orton\", \"Bernard-Marie Koltès\"]}\n",
      "\n",
      "[[ ## observation_3 ## ]]\n",
      "Failed to execute: Arg titles is not in the tool's args.\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## titles ## ]]` (must be formatted as a valid Python list[str]), and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## reasoning ## ]]\n",
      "The claim states that the author of the 1960s unproduced script written for The Beatles, Up Against It, and Bernard-Marie Koltès are both playwrights. We first searched for the author of the script and found that it was Joe Orton. Then, we checked if Joe Orton was a playwright and found that he was an English playwright and author. Next, we verified that Bernard-Marie Koltès was also a playwright. This verifies the claim.\n",
      "\n",
      "[[ ## titles ## ]]\n",
      "[\"Joe Orton\", \"Bernard-Marie Koltès\", \"Up Against It\", \"The Beatles\", \"Playwrights\"]\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# view the optimized prompts\n",
    "dspy.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the optimized prompts!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Joe Orton',\n",
       " 'Bernard-Marie Koltès',\n",
       " 'Up Against It',\n",
       " 'The Beatles',\n",
       " 'Playwrights']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimized_react.save(\"optimized_react.json\")\n",
    "\n",
    "loaded_react = dspy.ReAct(\"claim -> titles: list[str]\", tools=[search_wikipedia, lookup_wikipedia], max_iters=20)\n",
    "loaded_react.load(\"optimized_react.json\")\n",
    "\n",
    "loaded_react(claim=\"The author of the 1960s unproduced script written for The Beatles, Up Against It, and Bernard-Marie Koltès are both playwrights.\").titles"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cookbook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
