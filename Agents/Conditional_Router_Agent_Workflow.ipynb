{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional Router Agent Workflow - Selecting the right LLM for the job\n",
    "Author: [Zain Hasan](https://x.com/ZainHasan6)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/togethercomputer/together-cookbook/blob/main/Agents/Conditional_Router_Agent_Workflow.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this notebook, we'll demonstrate how to program an agent workflow that dynamically selects LLMs based on their specialties and task requirements.\n",
    "\n",
    "For example, coding tasks might use specialized models like Qwen coder or DeepSeek 2.5, while planning or reasoning tasks could leverage different models optimized for those purposes.\n",
    "\n",
    "To achieve this, we'll create:\n",
    "\n",
    "1. LLM Router: A language model that selects and justifies the best model for a given task\n",
    "2. Simple API that executes the chosen model and solves the task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Router Agent Workflow\n",
    "\n",
    "<img src=\"../images/if_router.png\" width=\"700\">\n",
    "\n",
    "In this **conditional router agent workflow**, we demonstrate how to program a router LLM that selects from multiple routes - including different LLMs, prompts, action sequences, or functionalities. Given a task and route preferences, it chooses one path and justifies its selection. This implementation activates only one path per LLM call.\n",
    "\n",
    "For our specific use case, selecting a model for a task follows these steps:\n",
    "\n",
    "1. Router LLM receives user prompt and route information, outputs JSON with `model_choice` and `reason`\n",
    "2. Simple LLM call executes `model_choice` and returns response\n",
    "\n",
    "Now let's see the coded implementation of this workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install libraries\n",
    "!pip install -qU pydantic together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import json\n",
    "import together\n",
    "from together import Together\n",
    "\n",
    "from typing import Any, Optional, Dict, List, Literal\n",
    "from pydantic import Field, BaseModel, ValidationError\n",
    "\n",
    "TOGETHER_API_KEY = \"--Your API Key--\"\n",
    "\n",
    "client = Together(api_key= TOGETHER_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple LLM call helper function\n",
    "def run_llm(user_prompt : str, model : str, system_prompt : Optional[str] = None):\n",
    "    \"\"\" Run the language model with the given user prompt and system prompt. \"\"\"\n",
    "    messages = []\n",
    "    if system_prompt:\n",
    "        messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "    \n",
    "    messages.append({\"role\": \"user\", \"content\": user_prompt})\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0.7,\n",
    "        max_tokens=4000,        \n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Simple JSON mode LLM call helper function\n",
    "def JSON_llm(user_prompt : str, schema : BaseModel, system_prompt : Optional[str] = None):\n",
    "    \"\"\" Run a language model with the given user prompt and system prompt, and return a structured JSON object. \"\"\"\n",
    "    try:\n",
    "        messages = []\n",
    "        if system_prompt:\n",
    "            messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "        \n",
    "        messages.append({\"role\": \"user\", \"content\": user_prompt})\n",
    "        \n",
    "        extract = client.chat.completions.create(\n",
    "            messages=messages,\n",
    "            model=\"meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo\",\n",
    "            response_format={\n",
    "                \"type\": \"json_object\",\n",
    "                \"schema\": schema.model_json_schema(),\n",
    "            },\n",
    "        )\n",
    "        \n",
    "        response = json.loads(extract.choices[0].message.content)\n",
    "        return response\n",
    "        \n",
    "    except ValidationError as e:\n",
    "        raise ValueError(f\"Schema validation failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Routing Agent Implementation\n",
    "\n",
    "The overall flow of what we need to implement will be as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Router LLM\n",
    "\n",
    "The router LLM will need to select a route - we will create a Pydantic class to capture all available routes. This class will serve as both a guide for the Router LLM's output format and enable parsing its response to execute the chosen model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "\n",
    "class ModelOutput(BaseModel):\n",
    "    model: Literal[\"deepseek-ai/DeepSeek-V3\",  # All model choices that can be selected\n",
    "                   \"Qwen/Qwen2.5-Coder-32B-Instruct\", \n",
    "                   \"Gryphe/MythoMax-L2-13b\", \n",
    "                   \"Qwen/QwQ-32B-Preview\",\n",
    "                   \"meta-llama/Llama-3.3-70B-Instruct-Turbo\"]\n",
    "    \n",
    "    reason: str = Field(   # We need the router to tell us why the model/route was selected\n",
    "        description=\"Reason why this model was selected for the task specified in the prompt/query.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'Qwen/Qwen2.5-Coder-32B-Instruct',\n",
       " 'reason': 'The task involves generating a Python code snippet, which falls under code generation tasks. The Qwen/Qwen2.5-Coder-32B-Instruct model is specifically designed for code generation tasks, making it the best choice for this task.'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will use the pydantic class to both structure the output prompt and to give the router LLM information about routes\n",
    "# This will help the router make a better decision on which model to select\n",
    "\n",
    "ROUTER_SYSTEM_PROMPT = \"\"\"Given a user prompt/query, select the best model from the available options to solve the task and provide a reason for your choice.\n",
    "Each model has different capabilities - select the best model for the task provided:\n",
    "- deepseek-ai/DeepSeek-V3: Good generic model to default to incase no better alternative is selected\n",
    "- Qwen/Qwen2.5-Coder-32B-Instruct: Best for code generation tasks\n",
    "- Gryphe/MythoMax-L2-13b: Best model for story-telling and role-play and fantasy tasks\n",
    "- Qwen/QwQ-32B-Preview: Best model for reasoning, math and muiltistep tasks\n",
    "- meta-llama/Llama-3.3-70B-Instruct-Turbo: Best model for general enterprise usecases and tasks\"\"\"\n",
    "\n",
    "ROUTER_PROMPT = \"Given a user prompt/query: {user_query}, select the best model from the available options to solve the task and provide a reason for your choice. Answer only in JSON format.\"\n",
    "\n",
    "prompt = \"Produce python code snippet to check to see if a number is prime or not.\"\n",
    "\n",
    "selected_model = JSON_llm(ROUTER_PROMPT.format(user_query=prompt),\n",
    "                            ModelOutput,\n",
    "                            system_prompt=ROUTER_SYSTEM_PROMPT)\n",
    "\n",
    "selected_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create a small function that we can execute for multiple tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function that will call the router and then the output llm model in sequence to generate a response to a user prompt.\n",
    "def run_router_workflow(user_prompt : str):\n",
    "    \n",
    "    # Which route to take\n",
    "    selected_model = JSON_llm(ROUTER_PROMPT.format(user_query=user_prompt),\n",
    "                            ModelOutput,\n",
    "                            system_prompt=ROUTER_SYSTEM_PROMPT)\n",
    "    \n",
    "    # Take that route and run the LLM model\n",
    "    response = run_llm(user_prompt= user_prompt, \n",
    "                   model = selected_model['model']\n",
    "    )\n",
    "    return selected_model['model'], selected_model['reason'], response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Produce python code snippet to check to see if a number is prime or not.\n",
      "========================================\n",
      "Selected Model: Qwen/Qwen2.5-Coder-32B-Instruct \n",
      " Reason: The task involves code generation, specifically producing a Python code snippet. The Qwen/Qwen2.5-Coder-32B-Instruct model is best suited for code generation tasks, making it the ideal choice for this prompt.\n",
      "========================================\n",
      "Response: Certainly! Below is a Python code snippet that checks if a given number is prime:\n",
      "\n",
      "```python\n",
      "def is_prime(n):\n",
      "    \"\"\"Check if a number is prime.\"\"\"\n",
      "    if n <= 1:\n",
      "        return False\n",
      "    if n <= 3:\n",
      "        return True\n",
      "    if n % 2 == 0 or n % 3 == 0:\n",
      "        return False\n",
      "    i = 5\n",
      "    while i * i <= n:\n",
      "        if n % i == 0 or n % (i + 2) == 0:\n",
      "            return False\n",
      "        i += 6\n",
      "    return True\n",
      "\n",
      "# Example usage:\n",
      "number = 29\n",
      "if is_prime(number):\n",
      "    print(f\"{number} is a prime number.\")\n",
      "else:\n",
      "    print(f\"{number} is not a prime number.\")\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "1. **Initial Checks**:\n",
      "   - Numbers less than or equal to 1 are not prime.\n",
      "   - Numbers 2 and 3 are prime.\n",
      "   - Any number divisible by 2 or 3 is not prime (except for 2 and 3 themselves).\n",
      "\n",
      "2. **Iterative Check**:\n",
      "   - We start checking from 5 and increment by 6 (i.e., check 5, 11, 17, ...) because all primes greater than 3 can be written in the form of 6k ± 1.\n",
      "   - For each number `i`, we check if `n` is divisible by `i` or `i + 2`.\n",
      "   - The loop continues as long as `i * i` is less than or equal to `n`.\n",
      "\n",
      "This method is efficient for checking the primality of numbers, especially for larger values.\n"
     ]
    }
   ],
   "source": [
    "model, reason, response = run_router_workflow(prompt)\n",
    "\n",
    "print(f\"Query: {prompt}\")\n",
    "print(20*'==')\n",
    "print(f\"Selected Model: {model} \\n Reason: {reason}\")\n",
    "print(20*'==')\n",
    "print(f\"Response: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generic Implementation\n",
    "\n",
    "Now that we know how the internals of this workflow execute we can write a more generic version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def router_workflow(input_query: str, routes : Dict[str, str]) -> str:\n",
    "    \"\"\" Given a `input_qeury` and a dictionary of `routes` containing options and details for each.\n",
    "    Selects the best model for the task and return the response from the model.\n",
    "    \"\"\"\n",
    "    ROUTER_PROMPT = \"\"\"Given a user prompt/query: {user_query}, select the best option out of the following routes:\n",
    "    {routes}. Answer only in JSON format.\"\"\"\n",
    "\n",
    "    # Create a schema from the routes dictionary\n",
    "    class Schema(BaseModel):\n",
    "        route: Literal[tuple(routes.keys())]\n",
    "    \n",
    "        reason: str = Field(\n",
    "            description=\"Short one-liner explanation why this route was selected for the task in the prompt/query.\"\n",
    "        )\n",
    "\n",
    "    # Call LLM to select route\n",
    "    selected_route = JSON_llm(ROUTER_PROMPT.format(user_query=input_query, routes=routes), Schema)\n",
    "    print(f\"Selcted route:{selected_route['route']}\\nReason: {selected_route['reason']}\\n\")\n",
    "\n",
    "    # Use LLM on selected route. \n",
    "    # Could also have different prompts that need to be used for each route.\n",
    "    response = run_llm(user_prompt= input_query, model = selected_route['route'])\n",
    "    print(f\"Response: {response}\\n\")\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1: Produce python snippet to check to see if a number is prime or not.\n",
      "\n",
      "========================================\n",
      "Selected route:Qwen/Qwen2.5-Coder-32B-Instruct\n",
      " Reason: The task requires generating a Python code snippet to check if a number is prime or not, which falls under code generation tasks.\n",
      "\n",
      "Response: Certainly! Below is a Python function that checks whether a given number is prime or not:\n",
      "\n",
      "```python\n",
      "def is_prime(n):\n",
      "    \"\"\"Check if a number is prime.\"\"\"\n",
      "    if n <= 1:\n",
      "        return False\n",
      "    if n <= 3:\n",
      "        return True\n",
      "    if n % 2 == 0 or n % 3 == 0:\n",
      "        return False\n",
      "    i = 5\n",
      "    while i * i <= n:\n",
      "        if n % i == 0 or n % (i + 2) == 0:\n",
      "            return False\n",
      "        i += 6\n",
      "    return True\n",
      "\n",
      "# Example usage:\n",
      "number = 29\n",
      "if is_prime(number):\n",
      "    print(f\"{number} is a prime number.\")\n",
      "else:\n",
      "    print(f\"{number} is not a prime number.\")\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "1. **Initial Checks**: \n",
      "   - Numbers less than or equal to 1 are not prime.\n",
      "   - Numbers 2 and 3 are prime.\n",
      "   \n",
      "2. **Divisibility Check**:\n",
      "   - If the number is divisible by 2 or 3, it is not prime.\n",
      "   \n",
      "3. **Loop through potential factors**:\n",
      "   - Starting from 5, check divisibility up to the square root of `n`.\n",
      "   - The loop increments by 6 each time, checking `i` and `i + 2` (i.e., 5 and 7, 11 and 13, etc.), because all primes greater than 3 can be written in the form of 6k ± 1.\n",
      "\n",
      "This method is efficient for checking primality for reasonably large numbers.\n",
      "\n",
      "Task 2: Plan and provide a short itenary for a 2 week vacation in Europe.\n",
      "\n",
      "========================================\n",
      "Seelction route:Qwen/QwQ-32B-Preview\n",
      " Reason: Planning and providing a short itinerary for a 2-week vacation in Europe requires reasoning, planning, and multi-step tasks.\n",
      "\n",
      "Response: Planning a 2-week vacation in Europe can be both exciting and overwhelming due to the vast number of options available. Europe is rich in history, culture, and natural beauty, offering something for every type of traveler. To make the most of your time, it's essential to prioritize the destinations that interest you the most and plan a balanced itinerary that allows for both exploration and relaxation.\n",
      "\n",
      "### Step-by-Step Planning Guide\n",
      "\n",
      "1. **Define Your Interests:**\n",
      "   - History and Culture: Museums, castles, historical sites.\n",
      "   - Nature and Outdoors: Mountains, beaches, national parks.\n",
      "   - Food and Wine: Culinary experiences, wine tastings.\n",
      "   - City Life: Shopping, nightlife, contemporary culture.\n",
      "\n",
      "2. **Choose Countries and Cities:**\n",
      "   - Consider visa requirements, language barriers, and travel time between destinations.\n",
      "   - Popular choices include France, Italy, Spain, Germany, the UK, and the Netherlands.\n",
      "\n",
      "3. **Plan Your Route:**\n",
      "   - Start from the main entry point (e.g., London, Paris, Amsterdam).\n",
      "   - Plan a route that minimizes backtracking and efficient travel between cities.\n",
      "   - Consider internal flights or train routes for faster travel.\n",
      "\n",
      "4. **Allocate Time per Destination:**\n",
      "   - Spend at least 2-3 days in each city to explore adequately.\n",
      "   - Allow for travel days between destinations.\n",
      "\n",
      "5. **Book Accommodations:**\n",
      "   - Choose accommodations based on location, budget, and preferences.\n",
      "   - Book in advance, especially during peak seasons.\n",
      "\n",
      "6. **Research Attractions and Activities:**\n",
      "   - Make a list of must-see sights and experiences in each destination.\n",
      "   - Consider purchasing tickets in advance for popular attractions.\n",
      "\n",
      "7. **Budgeting:**\n",
      "   - Estimate costs for flights, accommodations, transportation, food, and activities.\n",
      "   - Set a daily budget to manage expenses.\n",
      "\n",
      "8. **Pack Smart:**\n",
      "   - Check the weather forecast for your destinations.\n",
      "   - Pack versatile clothing and comfortable shoes.\n",
      "   - Bring essential travel documents and copies.\n",
      "\n",
      "### Sample Itinerary\n",
      "\n",
      "#### Week 1: France and Italy\n",
      "\n",
      "**Day 1-3: Paris, France**\n",
      "- Arrival in Paris.\n",
      "- Visit the Eiffel Tower, Louvre Museum, and Notre-Dame Cathedral.\n",
      "- Stroll along the Champs-Élysées and enjoy French cuisine.\n",
      "\n",
      "**Day 4-6: Florence, Italy**\n",
      "- Fly from Paris to Florence.\n",
      "- Explore the Uffizi Gallery, Ponte Vecchio, and the Duomo.\n",
      "- Take a day trip to Tuscany for vineyard tours.\n",
      "\n",
      "**Day 7-9: Rome, Italy**\n",
      "- Travel from Florence to Rome by train.\n",
      "- Visit the Colosseum, Roman Forum, and Vatican City.\n",
      "- Enjoy pizza and gelato in Trastevere.\n",
      "\n",
      "#### Week 2: Spain and Portugal\n",
      "\n",
      "**Day 10-12: Barcelona, Spain**\n",
      "- Fly from Rome to Barcelona.\n",
      "- See Gaudí’s Sagrada Família, Park Güell, and Casa Batlló.\n",
      "- Relax on the beaches of Barceloneta.\n",
      "\n",
      "**Day 13-15: Lisbon, Portugal**\n",
      "- Travel from Barcelona to Lisbon by train or flight.\n",
      "- Explore Belem Tower, Jerónimos Monastery, and Alfama district.\n",
      "- Take a tram to Cristo Rei and enjoy Fado music.\n",
      "\n",
      "**Day 16: Departure**\n",
      "- Transfer to the airport for your return flight.\n",
      "\n",
      "### Tips for a Smooth Trip\n",
      "\n",
      "- **Travel Light:** Carry a backpack or rolling suitcase for ease of movement.\n",
      "- **Stay Connected:** Consider getting a local SIM card or international data plan.\n",
      "- **Learn Basic Phrases:** Knowing a few words in the local language can be helpful.\n",
      "- **Stay Flexible:** Be prepared for changes in plans due to weather or other factors.\n",
      "- **Enjoy the Journey:** Take time to soak in the culture and meet new people.\n",
      "\n",
      "Europe is a continent filled with diverse experiences, and a well-planned itinerary can ensure that you make the most of your two-week adventure. Whether you're exploring historic cities, indulging in local cuisine, or relaxing in natural美景, Europe has something to offer every traveler.\n",
      "\n",
      "Task 3: Write a short story about a dragon and a knight.\n",
      "\n",
      "========================================\n",
      "Seelction route:Gryphe/MythoMax-L2-13b\n",
      " Reason: The task requires story-telling and fantasy, which is best suited for the Gryphe/MythoMax-L2-13b model.\n",
      "\n",
      "Response: \n",
      " In a faraway kingdom, there once lived a mighty dragon named Drako. He was known for his fiery breath and sharp claws, terrorizing the nearby villages and towns. The king of the land decided to send his bravest knight, Sir William, to slay the beast and bring peace to his people.\n",
      "Sir William set out on his quest, armed with his sword and shield. After days of riding through the dense forest, he finally saw the dragon's lair. The knight dismounted from his horse and slowly approached the cave entrance. He took a deep breath, bracing himself for the battle ahead.\n",
      "As he stepped into the dark cave, he heard a loud roar that sent shivers down his spine. The dragon emerged from the shadows, its fiery eyes fixed on the knight. The beast let out another deafening roar, and Sir William readied his sword.\n",
      "What happened next surprised everyone. Instead of attacking, Drako spoke to the knight. He told him about how lonely he had been, how he had been driven to terrorize the kingdom out of desperation. Sir William listened intently, realizing that the dragon was not inherently evil but rather misunderstood.\n",
      "The knight proposed a truce between them, offering to help Drako find a new home and food if he promised to stop terrorizing the towns. Drako agreed, and together they left the cave.\n",
      "The people of the kingdom were amazed to see the dragon and the knight walking side by side. Sir William explained what had happened, and the king agreed to the truce. Drako was given a new home in a remote part of the kingdom, far away from the towns, and he was provided with food to sustain him.\n",
      "From that day forward, the dragon and the knight became unlikely friends. They would often visit each other, and the people of the kingdom knew that they were safe from harm. The legend of the dragon and the knight lived on, teaching everyone that even the fiercest of enemies could become friends if given the chance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "\n",
    "prompt_list = [\"Produce python snippet to check to see if a number is prime or not.\",\n",
    "               \"Plan and provide a short itenary for a 2 week vacation in Europe.\",\n",
    "               \"Write a short story about a dragon and a knight.\"]\n",
    "\n",
    "model_routes = { # feel free to add more models and their descriptions\n",
    "    \"Qwen/Qwen2.5-Coder-32B-Instruct\" : \"Best model choice for code generation tasks.\",\n",
    "    \"Gryphe/MythoMax-L2-13b\" : \"Best model choice for story-telling, role-playing and fantasy tasks.\",\n",
    "    \"Qwen/QwQ-32B-Preview\" : \"Best model for reasoning, planning and muilti-step tasks\",\n",
    "}\n",
    "\n",
    "for i, prompt in enumerate(prompt_list):\n",
    "    print(f\"Task {i+1}: {prompt}\\n\")\n",
    "    print(20*'==')\n",
    "    router_workflow(prompt, model_routes)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
