{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H3Ynz4lIMCep"
   },
   "source": [
    "# Multiturn Conversation Finetuning\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/togethercomputer/together-cookbook/blob/main/Multiturn_Conversation_Finetuning.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dlayKrcUMCeq"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "In this cookbook we demonstrate how you can train your LLM to converse better by finetuning it on multi-step conversational data. This cookbook is part of a technical deep dive blogpost you can read [here](https://www.together.ai/blog/fine-tuning-llms-for-multi-turn-conversations-a-technical-deep-dive).\n",
    "\n",
    "[CoQA](https://huggingface.co/datasets/stanfordnlp/coqa/tree/main) is a large-scale dataset for building Conversational Question Answering systems. The goal of the CoQA challenge is to measure the ability of machines to understand a text passage and answer a series of interconnected questions that appear in a conversation.\n",
    "\n",
    "CoQA contains 127,000+ questions with answers collected from 8000+ conversations. Each conversation is collected by pairing two crowdworkers to chat about a passage in the form of questions and answers. CoQA has a lot of challenging phenomena not present in existing reading comprehension datasets, e.g., coreference and pragmatic reasoning.\n",
    "\n",
    "<img src=\"images/conversation.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FzUwYWmOMCeq"
   },
   "source": [
    "## Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q datasets==3.1.0 transformers together==1.3.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mcwtn8OnMCer"
   },
   "source": [
    "## Prepare CoQA Dataset for Fine-tuning\n",
    "\n",
    "Below we load and prepare the CoQA dataset for fine-tuning through the Together AI fine-tuning API.\n",
    "\n",
    "The code below will format the data to a common conversational format, that can be used for fine-tuning the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "coqa_dataset = load_dataset(\"stanfordnlp/coqa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zCNmZkSZNrOS"
   },
   "source": [
    "### Lets examine some rows from the CoQA dataset.\n",
    "\n",
    "We can see that the source passage in which the questions and answers are observed in the `story` column. The `questions` column contains multiple questions and the `answers` column contains a dictionary of answers and also source citation of where the answer starts and ends in the source passage.\n",
    "\n",
    "The goal of the CoQA challenge is to measure the ability of machines to understand a text passage and answer a series of interconnected questions that appear in a conversation.\n",
    "\n",
    "This ability can be assessed using two metrics: F1 score, which measures word overlap between predicted and ground truth answers, and Exact Match (EM), which requires the prediction to exactly match one of the ground truth answers.\n",
    "\n",
    "<img src=\"images/CoQA.png\" height=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "5E3sRQrUM44i",
    "outputId": "0906f99e-71ff-45ac-b960-92012bb68273"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"coqa_dataset[\\\"train\\\"]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"wikipedia\",\n          \"cnn\",\n          \"gutenberg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"story\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"New York (CNN) -- More than 80 Michael Jackson collectibles -- including the late pop star's famous rhinestone-studded glove from a 1983 performance -- were auctioned off Saturday, reaping a total $2 million. \\n\\nProfits from the auction at the Hard Rock Cafe in New York's Times Square crushed pre-sale expectations of only $120,000 in sales. \\n\\nThe highly prized memorabilia, which included items spanning the many stages of Jackson's career, came from more than 30 fans, associates and family members, who contacted Julien's Auctions to sell their gifts and mementos of the singer. \\n\\nJackson's flashy glove was the big-ticket item of the night, fetching $420,000 from a buyer in Hong Kong, China. Jackson wore the glove at a 1983 performance during \\\"Motown 25,\\\" an NBC special where he debuted his revolutionary moonwalk. \\n\\nFellow Motown star Walter \\\"Clyde\\\" Orange of the Commodores, who also performed in the special 26 years ago, said he asked for Jackson's autograph at the time, but Jackson gave him the glove instead. \\n\\n\\\"The legacy that [Jackson] left behind is bigger than life for me,\\\" Orange said. \\\"I hope that through that glove people can see what he was trying to say in his music and what he said in his music.\\\" \\n\\nOrange said he plans to give a portion of the proceeds to charity. \\n\\nHoffman Ma, who bought the glove on behalf of Ponte 16 Resort in Macau, paid a 25 percent buyer's premium, which was tacked onto all final sales over $50,000. Winners of items less than $50,000 paid a 20 percent premium. \",\n          \"CHAPTER XXIV. THE INTERRUPTED MASS \\n\\nThe morning of that Wednesday of Corpus Christi, fateful to all concerned in this chronicle, dawned misty and grey, and the air was chilled by the wind that blew from the sea. The chapel bell tinkled out its summons, and the garrison trooped faithfully to Mass. \\n\\nPresently came Monna Valentina, followed by her ladies, her pages, and lastly, Peppe, wearing under his thin mask of piety an air of eager anxiety and unrest. Valentina was very pale, and round her eyes there were dark circles that told of sleeplessness, and as she bowed her head in prayer, her ladies observed that tears were falling on the illuminated Mass-book over which she bent. And now came Fra Domenico from the sacristy in the white chasuble that the Church ordains for the Corpus Christi feast, followed by a page in a clerkly gown of black, and the Mass commenced. \\n\\nThere were absent only from the gathering Gonzaga and Fortemani, besides a sentry and the three prisoners. Francesco and his two followers. \\n\\nGonzaga had presented himself to Valentina with the plausible tale that, as the events of which Fanfulla's letter had given them knowledge might lead Gian Maria at any moment to desperate measures, it might be well that he should reinforce the single man-at-arms patrolling the walls. Valentina, little recking now whether the castle held or fell, and still less such trifles as Gonzaga's attendance at Mass, had assented without heeding the import of what he said. \\n\\nAnd so, his face drawn and his body quivering with the excitement of what he was about to do, Gonzaga had repaired to the ramparts so soon as he had seen them all safely into chapel. The sentinel was that same clerkly youth Aventano, who had read to the soldiers that letter Gian Maria had sent Gonzaga. This the courtier accepted as a good omen. If a man there was among the soldiery at Roccaleone with whom he deemed that he had an account to settle, that man was Aventano. \",\n          \"CHAPTER VII. THE DAUGHTER OF WITHERSTEEN \\n\\n\\\"Lassiter, will you be my rider?\\\" Jane had asked him. \\n\\n\\\"I reckon so,\\\" he had replied. \\n\\nFew as the words were, Jane knew how infinitely much they implied. She wanted him to take charge of her cattle and horse and ranges, and save them if that were possible. Yet, though she could not have spoken aloud all she meant, she was perfectly honest with herself. Whatever the price to be paid, she must keep Lassiter close to her; she must shield from him the man who had led Milly Erne to Cottonwoods. In her fear she so controlled her mind that she did not whisper this Mormon's name to her own soul, she did not even think it. Besides, beyond this thing she regarded as a sacred obligation thrust upon her, was the need of a helper, of a friend, of a champion in this critical time. If she could rule this gun-man, as Venters had called him, if she could even keep him from shedding blood, what strategy to play his flame and his presence against the game of oppression her churchmen were waging against her? Never would she forget the effect on Tull and his men when Venters shouted Lassiter's name. If she could not wholly control Lassiter, then what she could do might put off the fatal day. \\n\\nOne of her safe racers was a dark bay, and she called him Bells because of the way he struck his iron shoes on the stones. When Jerd led out this slender, beautifully built horse Lassiter suddenly became all eyes. A rider's love of a thoroughbred shone in them. Round and round Bells he walked, plainly weakening all the time in his determination not to take one of Jane's favorite racers. \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"questions\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answers\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-23c33a5e-99a0-4d11-aa23-f56986f1fa90\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>story</th>\n",
       "      <th>questions</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wikipedia</td>\n",
       "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
       "      <td>[When was the Vat formally opened?, what is th...</td>\n",
       "      <td>{'input_text': ['It was formally established i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cnn</td>\n",
       "      <td>New York (CNN) -- More than 80 Michael Jackson...</td>\n",
       "      <td>[Where was the Auction held?, How much did the...</td>\n",
       "      <td>{'input_text': ['Hard Rock Cafe', '$2 million....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gutenberg</td>\n",
       "      <td>CHAPTER VII. THE DAUGHTER OF WITHERSTEEN \\n\\n\"...</td>\n",
       "      <td>[What did Venters call Lassiter?, Who asked La...</td>\n",
       "      <td>{'input_text': ['gun-man', 'Jane', 'Yes', 'to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cnn</td>\n",
       "      <td>(CNN) -- The longest-running holiday special s...</td>\n",
       "      <td>[Who is Rudolph's father?, Why does Rudolph ru...</td>\n",
       "      <td>{'input_text': ['Donner', 'he felt like an out...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gutenberg</td>\n",
       "      <td>CHAPTER XXIV. THE INTERRUPTED MASS \\n\\nThe mor...</td>\n",
       "      <td>[Who arrived at the church?, Who was followed ...</td>\n",
       "      <td>{'input_text': ['the garrison first', 'Fra. Do...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-23c33a5e-99a0-4d11-aa23-f56986f1fa90')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-23c33a5e-99a0-4d11-aa23-f56986f1fa90 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-23c33a5e-99a0-4d11-aa23-f56986f1fa90');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-87aadf1b-59f7-4e17-a172-ebacc31bf3d1\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-87aadf1b-59f7-4e17-a172-ebacc31bf3d1')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-87aadf1b-59f7-4e17-a172-ebacc31bf3d1 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "      source                                              story  \\\n",
       "0  wikipedia  The Vatican Apostolic Library (), more commonl...   \n",
       "1        cnn  New York (CNN) -- More than 80 Michael Jackson...   \n",
       "2  gutenberg  CHAPTER VII. THE DAUGHTER OF WITHERSTEEN \\n\\n\"...   \n",
       "3        cnn  (CNN) -- The longest-running holiday special s...   \n",
       "4  gutenberg  CHAPTER XXIV. THE INTERRUPTED MASS \\n\\nThe mor...   \n",
       "\n",
       "                                           questions  \\\n",
       "0  [When was the Vat formally opened?, what is th...   \n",
       "1  [Where was the Auction held?, How much did the...   \n",
       "2  [What did Venters call Lassiter?, Who asked La...   \n",
       "3  [Who is Rudolph's father?, Why does Rudolph ru...   \n",
       "4  [Who arrived at the church?, Who was followed ...   \n",
       "\n",
       "                                             answers  \n",
       "0  {'input_text': ['It was formally established i...  \n",
       "1  {'input_text': ['Hard Rock Cafe', '$2 million....  \n",
       "2  {'input_text': ['gun-man', 'Jane', 'Yes', 'to ...  \n",
       "3  {'input_text': ['Donner', 'he felt like an out...  \n",
       "4  {'input_text': ['the garrison first', 'Fra. Do...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coqa_dataset[\"train\"].to_pandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "83vpjqqaP0qC"
   },
   "source": [
    "### Format the data to conform with the chat format:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"messages\": [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful AI chatbot.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hello, how are you?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"I'm doing well, thank you! How can I help you?\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you explain machine learning?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Machine learning is...\"}\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "This list of messages can then be written to a `.jsonl` file. \n",
    "\n",
    "To learn more about the conversation format please see our [docs](https://docs.together.ai/docs/fine-tuning-data-preparation#conversational-data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TyMaBtwFMCes"
   },
   "outputs": [],
   "source": [
    "# the system prompt,if present, must always be at the beginning\n",
    "system_prompt = \"Read the story and extract answers for the questions.\\nStory: {}\"\n",
    "\n",
    "def map_fields(row):\n",
    "    \"\"\"    \n",
    "    Maps the fields from a row of data to a structured format for conversation.\n",
    "    Args:\n",
    "        row (dict): A dictionary containing the keys \"story\", \"questions\", and \"answers\".\n",
    "            - \"story\" (str): The story content to be used in the system prompt.\n",
    "            - \"questions\" (list of str): A list of questions from the user.\n",
    "            - \"answers\" (dict): A dictionary containing the key \"input_text\" which is a list of answers from the assistant.\n",
    "    Returns:\n",
    "        dict: A dictionary with a single key \"messages\" which is a list of message dictionaries.\n",
    "            Each message dictionary contains:\n",
    "            - \"role\" (str): The role of the message sender, either \"system\", \"user\", or \"assistant\".\n",
    "            - \"content\" (str): The content of the message.    \n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_prompt.format(row[\"story\"]),\n",
    "        }\n",
    "    ]\n",
    "    for q, a in zip(row[\"questions\"], row[\"answers\"][\"input_text\"]):\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": q,\n",
    "            }\n",
    "        )\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": a,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        \"messages\": messages\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RTFiLensMCes"
   },
   "outputs": [],
   "source": [
    "# transform the data using the mapping function\n",
    "train_messages = coqa_dataset[\"train\"].map(map_fields, remove_columns=coqa_dataset[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TuUm9Xc1b3-L",
    "outputId": "df1c0322-b543-416d-e91d-ef7a5b5961e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['messages'],\n",
       "    num_rows: 7199\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "7168d48e72e746a1a6464b7b48a5d870",
      "1c895a8018d04c9292f25284d0204c7f",
      "35cfd6581b1348f6a116ca12b7972749",
      "d970cacabdb14c5ebbbd7d669cc7e78c",
      "5a31e3e96e8b43e993d184743be95681",
      "52514ac3acdb4afd8d4011e6318f1364",
      "4ebde01e42ac49a2aec86b0436e87e1b",
      "88a6cb16b4834fbdac9508081a91c780",
      "9a2e7bbf590e48de832f9b351a4c5999",
      "f6861d87d24a41279590910f6b2464a3",
      "c521c99648414732b99fc773df821e24"
     ]
    },
    "id": "g48rkKcGMCet",
    "outputId": "46ac92cf-a64e-4dc3-c3eb-01e5309392dc"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7168d48e72e746a1a6464b7b48a5d870",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "23777505"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_messages.to_json(\"coqa_prepared_train.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KzR7iEfGMCet"
   },
   "source": [
    "## Fine-tune on Prepared Dataset using Together AI Fine-tuning API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "4TtT_YdRMCet"
   },
   "outputs": [],
   "source": [
    "from together import Together\n",
    "import os\n",
    "\n",
    "TOGETHER_API_KEY = os.getenv(\"TOGETHER_API_KEY\")\n",
    "WANDB_API_KEY = os.getenv(\"WANDB_API_KEY\")\n",
    "\n",
    "\n",
    "client = Together(api_key=TOGETHER_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jxEdLIyNMCet",
    "outputId": "44809413-badb-42e9-cf7c-e650601b2691"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading file coqa_prepared_train.jsonl: 100%|██████████| 23.8M/23.8M [00:01<00:00, 23.3MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id='file-63b9f097-e582-4d2e-941e-4b541aa7e328' object=<ObjectType.File: 'file'> created_at=1731886046 type=None purpose=<FilePurpose.FineTune: 'fine-tune'> filename='coqa_prepared_train.jsonl' bytes=0 line_count=0 processed=False FileType='jsonl'\n"
     ]
    }
   ],
   "source": [
    "# Upload dataset to Together AI\n",
    "\n",
    "train_file_resp = client.files.upload(\"coqa_prepared_train.jsonl\", check=True)\n",
    "print(train_file_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_resp = client.fine_tuning.create(\n",
    "    training_file = train_file_resp.id,\n",
    "    model = 'meta-llama/Meta-Llama-3.1-8B-Instruct-Reference',\n",
    "    train_on_inputs= \"auto\",\n",
    "    n_epochs = 3,\n",
    "    n_checkpoints = 1,\n",
    "    wandb_api_key = WANDB_API_KEY,\n",
    "    lora = True,\n",
    "    warmup_ratio=0,\n",
    "    learning_rate = 1e-5,\n",
    "    suffix = 'my-demo-finetune',\n",
    ")\n",
    "\n",
    "print(ft_resp.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the fine-tuning job is completed you will be able to see it in your [Together AI dashbaord](https://api.together.ai)\n",
    "\n",
    "<img src=\"images/ft_model.png\" height=\"500\">\n",
    "\n",
    "You can also look at the WandB plots for the run(if a WANDB key was provided):\n",
    "\n",
    "<img src=\"images/wandb_model.png\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Fine-tuned Model\n",
    "\n",
    "For evaluation, CoQA uses two metrics: \n",
    "- F1 score, which measures word overlap between predicted and ground truth answers\n",
    "- Exact Match (EM), which requires the prediction to exactly match one of the ground truth answers. \n",
    "\n",
    "F1 is the primary metric as it better handles free-form answers by giving partial credit for partially correct responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TvF1i0GqMCet"
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from multiprocessing.pool import ThreadPool\n",
    "import transformers.data.metrics.squad_metrics as squad_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QxMrCnumMCeu"
   },
   "outputs": [],
   "source": [
    "# This function is used to generate model answers on the CoQA validation set from the untuned reference and fine-tuned models\n",
    "\n",
    "def get_model_answers(model_name):\n",
    "    \"\"\"\n",
    "    Generate model answers for a given model name using a dataset of questions and answers.\n",
    "    Args:\n",
    "        model_name (str): The name of the model to use for generating answers.\n",
    "    Returns:\n",
    "        list: A list of lists, where each inner list contains the answers generated by the model for the corresponding set of questions in the dataset.\n",
    "    The function performs the following steps:\n",
    "    1. Initializes an empty list to store the model answers.\n",
    "    2. Defines an inner function `get_answers` that takes a data dictionary and generates answers for the questions in the data.\n",
    "    3. Uses a thread pool to parallelize the process of generating answers for each entry in the validation dataset.\n",
    "    4. Appends the generated answers to the `model_answers` list.\n",
    "    5. Returns the `model_answers` list.\n",
    "    Note:\n",
    "        - The `system_prompt` and `client` variables are assumed to be defined elsewhere in the code.\n",
    "        - The `coqa_dataset` variable is assumed to contain the dataset with a \"validation\" key.\n",
    "    \"\"\"\n",
    "\n",
    "    model_answers = []\n",
    "\n",
    "    def get_answers(data):\n",
    "        answers = []\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt.format(data[\"story\"]),\n",
    "            }\n",
    "        ]\n",
    "        for q, true_answer in zip(data[\"questions\"], data[\"answers\"][\"input_text\"]):\n",
    "            messages.append(\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": q\n",
    "                }\n",
    "            )\n",
    "            chat_completion = client.chat.completions.create(\n",
    "                messages=messages,\n",
    "                model=model_name,\n",
    "                max_tokens=64,\n",
    "            )\n",
    "            answer = chat_completion.choices[0].message.content\n",
    "            answers.append(answer)\n",
    "        return answers\n",
    "\n",
    "\n",
    "    with ThreadPool(8) as pool:\n",
    "        for answers in tqdm(pool.imap(get_answers, coqa_dataset[\"validation\"]), total=len(coqa_dataset[\"validation\"])):\n",
    "            model_answers.append(answers)\n",
    "\n",
    "    return model_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EJ_DtH1dMCeu"
   },
   "outputs": [],
   "source": [
    "# This function will be used to evaluate predicted answers uinsg the Exact Match (EM) and F1 metrics\n",
    "\n",
    "def get_metrics(pred_answers):\n",
    "    \"\"\"\n",
    "    Calculate the Exact Match (EM) and F1 metrics for predicted answers.\n",
    "    Args:\n",
    "        pred_answers (list): A list of predicted answers. Each element in the list is a list of predicted answers for a single question.\n",
    "    Returns:\n",
    "        tuple: A tuple containing two elements:\n",
    "            - em_score (float): The average Exact Match score across all predictions.\n",
    "            - f1_score (float): The average F1 score across all predictions.\n",
    "    \"\"\"\n",
    "\n",
    "    em_metrics = []\n",
    "    f1_metrics = []\n",
    "\n",
    "    for pred, data in tqdm(zip(pred_answers, coqa_dataset[\"validation\"]), total=len(pred_answers)):\n",
    "        for pred_answer, true_answer in zip(pred, data[\"answers\"][\"input_text\"]):\n",
    "            em_metrics.append(squad_metrics.compute_exact(true_answer, pred_answer))\n",
    "            f1_metrics.append(squad_metrics.compute_f1(true_answer, pred_answer))\n",
    "\n",
    "    return sum(em_metrics) / len(em_metrics), sum(f1_metrics) / len(f1_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Model and Run Evals\n",
    "\n",
    "Before we can run the evaluations we need to deploy our finetuned model as a Dedicated Endpoint(DE). After fine-tuning completes, access your model through the Together AI dashboard. Go to Models, select your fine-tuned model, and select Deploy. Choose from the available hardware options - we'll use a single A100-80GB GPU for this example.\n",
    "\n",
    "<img src=\"images/deploy_CFT.png\" height=\"650\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HdXygvuEMCeu"
   },
   "outputs": [],
   "source": [
    "models_names = [\n",
    "    \"meta-llama/Meta-Llama-3.1-8B-Instruct-Reference\",\n",
    "    \"zainhas/Meta-Llama-3.1-8B-Instruct-Reference-my-demo-finetune-4224205a\", # finetuned model goes here once deployed\n",
    "]\n",
    "\n",
    "for model_name in models_names:\n",
    "    print(model_name)\n",
    "    answers = get_model_answers(model_name)\n",
    "    em_metric, f1_metric = get_metrics(answers)\n",
    "    print(f\"EM: {em_metric}, F1: {f1_metric}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the evaluation above we saw a marked improvement in the LLMs ability to address conversational questions. The exact match score ~12x and the F1 score goes up ~3x after fine-tuning.\n",
    "\n",
    "| Llama 3.1 8B | EM | F1|\n",
    "|---|---|---|\n",
    "| Original | 0.043 | 0.232 |\n",
    "| Fine-tuned | 0.62 | 0.78 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn more about our fine-tuning API read the docs [here](https://docs.together.ai/reference/finetune)!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1c895a8018d04c9292f25284d0204c7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_52514ac3acdb4afd8d4011e6318f1364",
      "placeholder": "​",
      "style": "IPY_MODEL_4ebde01e42ac49a2aec86b0436e87e1b",
      "value": "Creating json from Arrow format: 100%"
     }
    },
    "1dd072f46b66426ca339e58fbc559d82": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_84a30840314549f89cc0fc1ce33cf401",
       "IPY_MODEL_25b089785b174e9ea849ca783e0a1c8b",
       "IPY_MODEL_969e66edb6104359b5dca4bcbe4d9f17"
      ],
      "layout": "IPY_MODEL_549f223972164c78a45ce6d6274ee1e3"
     }
    },
    "1ec954a2637144018c9e60bc230841cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "25b089785b174e9ea849ca783e0a1c8b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_564a6192c21b4fbd8c6c5452a1cca0e4",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_54c73a67cab24e2399215831cf509dff",
      "value": 1
     }
    },
    "35cfd6581b1348f6a116ca12b7972749": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_88a6cb16b4834fbdac9508081a91c780",
      "max": 8,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9a2e7bbf590e48de832f9b351a4c5999",
      "value": 8
     }
    },
    "4ebde01e42ac49a2aec86b0436e87e1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "52514ac3acdb4afd8d4011e6318f1364": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "549f223972164c78a45ce6d6274ee1e3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "54c73a67cab24e2399215831cf509dff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "564a6192c21b4fbd8c6c5452a1cca0e4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5a31e3e96e8b43e993d184743be95681": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7168d48e72e746a1a6464b7b48a5d870": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1c895a8018d04c9292f25284d0204c7f",
       "IPY_MODEL_35cfd6581b1348f6a116ca12b7972749",
       "IPY_MODEL_d970cacabdb14c5ebbbd7d669cc7e78c"
      ],
      "layout": "IPY_MODEL_5a31e3e96e8b43e993d184743be95681"
     }
    },
    "84a30840314549f89cc0fc1ce33cf401": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c95e7176741640dfb94219ace2e11f28",
      "placeholder": "​",
      "style": "IPY_MODEL_c51f0ebd59054d47a6148abf5e331412",
      "value": "Creating json from Arrow format: 100%"
     }
    },
    "88a6cb16b4834fbdac9508081a91c780": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "969e66edb6104359b5dca4bcbe4d9f17": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_96a87bab58d44d2c947fd123482c97d2",
      "placeholder": "​",
      "style": "IPY_MODEL_1ec954a2637144018c9e60bc230841cf",
      "value": " 1/1 [00:00&lt;00:00, 28.78ba/s]"
     }
    },
    "96a87bab58d44d2c947fd123482c97d2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9a2e7bbf590e48de832f9b351a4c5999": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c51f0ebd59054d47a6148abf5e331412": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c521c99648414732b99fc773df821e24": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c95e7176741640dfb94219ace2e11f28": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d970cacabdb14c5ebbbd7d669cc7e78c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f6861d87d24a41279590910f6b2464a3",
      "placeholder": "​",
      "style": "IPY_MODEL_c521c99648414732b99fc773df821e24",
      "value": " 8/8 [00:01&lt;00:00,  5.73ba/s]"
     }
    },
    "f6861d87d24a41279590910f6b2464a3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "state": {}
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
